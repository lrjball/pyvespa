{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "d551cc4e",
            "metadata": {
                "id": "b3ae8a2b"
            },
            "source": []
        },
        {
            "cell_type": "markdown",
            "id": "0dd50339",
            "metadata": {},
            "source": [
                "<picture>\n",
                "  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://assets.vespa.ai/logos/Vespa-logo-green-RGB.svg\">\n",
                "  <source media=\"(prefers-color-scheme: light)\" srcset=\"https://assets.vespa.ai/logos/Vespa-logo-dark-RGB.svg\">\n",
                "  <img alt=\"#Vespa\" width=\"200\" src=\"https://assets.vespa.ai/logos/Vespa-logo-dark-RGB.svg\" style=\"margin-bottom: 25px;\">\n",
                "</picture>\n",
                "\n",
                "# Using Mixedbread.ai embedding model with support for binary vectors\n",
                "\n",
                "Check out the amazing blog post: [Binary and Scalar Embedding Quantization for Significantly Faster & Cheaper Retrieval](https://huggingface.co/blog/embedding-quantization)\n",
                "\n",
                "Binarization is significant because:\n",
                "\n",
                "- Binarization reduces the storage footprint from 1024 floats (4096 bytes) per vector to 128 int8 (128 bytes).\n",
                "- 32x less data to store\n",
                "- Faster distance calculations using [hamming](https://docs.vespa.ai/en/reference/schema-reference.html#distance-metric) distance, which\n",
                "  Vespa natively supports for bits packed into int8 precision. More on [hamming distance in Vespa](https://docs.vespa.ai/en/reference/schema-reference.html#hamming).\n",
                "\n",
                "Vespa supports `hamming` distance with and without [hnsw indexing](https://docs.vespa.ai/en/approximate-nn-hnsw.html).\n",
                "\n",
                "For those wanting to learn more about binary vectors, we recommend our 2021 blog series on [Billion-scale vector search with Vespa](https://blog.vespa.ai/billion-scale-knn/)\n",
                "and [Billion-scale vector search with Vespa - part two](https://blog.vespa.ai/billion-scale-knn-part-two/).\n",
                "\n",
                "This notebook demonstrates how to use the Mixedbread [mixedbread-ai/mxbai-embed-large-v1](https://huggingface.co/mixedbread-ai/mxbai-embed-large-v1) model\n",
                "with support for binary vectors with Vespa. The notebook example also\n",
                "includes a re-ranking phase that uses the float query vector version for improved accuracy. The re-ranking step makes the model perform at 96.45% of the full float version, with a 32x decrease in storage footprint.\n",
                "\n",
                "![img](https://pbs.twimg.com/media/GJSSTkvXAAAMrIQ?format=png&name=900x900)\n",
                "\n",
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vespa-engine/pyvespa/blob/master/docs/sphinx/source/examples/mixedbread-binary-embeddings-with-sentence-transformers-cloud.ipynb)\n",
                "\n",
                "Install the dependencies:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "daf34cf5",
            "metadata": {
                "id": "4ffa3cbe"
            },
            "outputs": [],
            "source": [
                "!pip3 install -U pyvespa sentence-transformers vespacli"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b3f11700",
            "metadata": {},
            "source": [
                "## Examining the embeddings using sentence-transformers\n",
                "\n",
                "Read the [blog post](https://huggingface.co/blog/embedding-quantization) for `sentence-transformer` usage.\n",
                "\n",
                "[sentence-transformer API](https://sbert.net/docs/package_reference/SentenceTransformer.html). Model card: [mixedbread-ai/mxbai-embed-large-v1](https://huggingface.co/mixedbread-ai/mxbai-embed-large-v1).\n",
                "\n",
                "Load the model using the sentence-transformers library:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "e2371493",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Default prompt name is set to 'retrieval'. This prompt will be applied to all `encode()` calls, except if `encode()` is called with `prompt` or `prompt_name` parameters.\n"
                    ]
                }
            ],
            "source": [
                "from sentence_transformers import SentenceTransformer\n",
                "\n",
                "model = SentenceTransformer(\n",
                "    \"mixedbread-ai/mxbai-embed-large-v1\",\n",
                "    prompts={\n",
                "        \"retrieval\": \"Represent this sentence for searching relevant passages: \",\n",
                "    },\n",
                "    default_prompt_name=\"retrieval\",\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3b68ebc1",
            "metadata": {},
            "source": [
                "### Some sample documents\n",
                "\n",
                "Define a few sample documents that we want to embed\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "c9b35db3",
            "metadata": {},
            "outputs": [],
            "source": [
                "documents = [\n",
                "    \"Alan Turing  was an English mathematician, computer scientist, logician, cryptanalyst, philosopher and theoretical biologist.\",\n",
                "    \"Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time.\",\n",
                "    \"Isaac Newton was an English polymath active as a mathematician, physicist, astronomer, alchemist, theologian, and author who was described in his time as a natural philosopher.\",\n",
                "    \"Marie Curie was a Polish and naturalised-French physicist and chemist who conducted pioneering research on radioactivity\",\n",
                "]"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "803d1a4d",
            "metadata": {},
            "source": [
                "Run embedding inference, notice how we specify `precision=\"binary\"`.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "d4edb2c7",
            "metadata": {},
            "outputs": [],
            "source": [
                "binary_embeddings = model.encode(documents, precision=\"binary\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "20baafcb",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Binary embedding shape (4, 128) with type int8\n"
                    ]
                }
            ],
            "source": [
                "print(\n",
                "    \"Binary embedding shape {} with type {}\".format(\n",
                "        binary_embeddings.shape, binary_embeddings.dtype\n",
                "    )\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "74ec69ca",
            "metadata": {
                "id": "da356d25"
            },
            "source": [
                "## Defining the Vespa application\n",
                "\n",
                "First, we define a [Vespa schema](https://docs.vespa.ai/en/schemas.html) with the fields we want to store and their type.\n",
                "\n",
                "Notice the `binary_vector` field that defines an indexed (dense) Vespa tensor with the dimension name `x[128]`.\n",
                "\n",
                "The indexing statement includes `index`\n",
                "which means that Vespa will use HNSW indexing for this field.\n",
                "\n",
                "Also notice the configuration of [distance-metric](https://docs.vespa.ai/en/reference/schema-reference.html#distance-metric) where we specify `hamming`.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "29105961",
            "metadata": {
                "executionInfo": {
                    "elapsed": 224,
                    "status": "ok",
                    "timestamp": 1706652002196,
                    "user": {
                        "displayName": "Andreas Eriksen",
                        "userId": "00161553861396505040"
                    },
                    "user_tz": -60
                },
                "id": "0dca2378"
            },
            "outputs": [],
            "source": [
                "from vespa.package import Schema, Document, Field, FieldSet\n",
                "\n",
                "my_schema = Schema(\n",
                "    name=\"doc\",\n",
                "    mode=\"index\",\n",
                "    document=Document(\n",
                "        fields=[\n",
                "            Field(\n",
                "                name=\"doc_id\",\n",
                "                type=\"string\",\n",
                "                indexing=[\"summary\", \"index\"],\n",
                "                match=[\"word\"],\n",
                "                rank=\"filter\",\n",
                "            ),\n",
                "            Field(\n",
                "                name=\"text\",\n",
                "                type=\"string\",\n",
                "                indexing=[\"summary\", \"index\"],\n",
                "                index=\"enable-bm25\",\n",
                "            ),\n",
                "            Field(\n",
                "                name=\"binary_vector\",\n",
                "                type=\"tensor<int8>(x[128])\",\n",
                "                indexing=[\"attribute\", \"index\"],\n",
                "                attribute=[\"distance-metric: hamming\"],\n",
                "            ),\n",
                "        ]\n",
                "    ),\n",
                "    fieldsets=[FieldSet(name=\"default\", fields=[\"text\"])],\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bed768cb",
            "metadata": {},
            "source": [
                "We must add the schema to a Vespa [application package](https://docs.vespa.ai/en/application-packages.html).\n",
                "This consists of configuration files, schemas, models, and possibly even custom code (plugins).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "c371b01f",
            "metadata": {
                "executionInfo": {
                    "elapsed": 239,
                    "status": "ok",
                    "timestamp": 1706652007584,
                    "user": {
                        "displayName": "Andreas Eriksen",
                        "userId": "00161553861396505040"
                    },
                    "user_tz": -60
                },
                "id": "66c5da1d"
            },
            "outputs": [],
            "source": [
                "from vespa.package import ApplicationPackage\n",
                "\n",
                "vespa_app_name = \"mixedbreadai\"\n",
                "vespa_application_package = ApplicationPackage(name=vespa_app_name, schema=[my_schema])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9a3fe087",
            "metadata": {
                "id": "7fe3d7bd"
            },
            "source": [
                "In the last step, we configure [ranking](https://docs.vespa.ai/en/ranking.html) by adding `rank-profile`'s to the schema.\n",
                "\n",
                "`unpack_bits` unpacks the binary representation into a 1024-dimensional float vector [doc](https://docs.vespa.ai/en/reference/ranking-expressions.html#unpack-bits).\n",
                "\n",
                "We define two tensor inputs, one compact binary representation that is used for the nearestNeighbor search and one\n",
                "full version that is used in ranking.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "a5d13c7f",
            "metadata": {
                "executionInfo": {
                    "elapsed": 407,
                    "status": "ok",
                    "timestamp": 1706652010412,
                    "user": {
                        "displayName": "Andreas Eriksen",
                        "userId": "00161553861396505040"
                    },
                    "user_tz": -60
                },
                "id": "a8ce5624"
            },
            "outputs": [],
            "source": [
                "from vespa.package import RankProfile, FirstPhaseRanking, SecondPhaseRanking, Function\n",
                "\n",
                "\n",
                "rerank = RankProfile(\n",
                "    name=\"rerank\",\n",
                "    inputs=[\n",
                "        (\"query(q_binary)\", \"tensor<int8>(x[128])\"),\n",
                "        (\"query(q_full)\", \"tensor<float>(x[1024])\"),\n",
                "    ],\n",
                "    functions=[\n",
                "        Function(  # this returns a tensor<float>(x[1024]) with values -1 or 1\n",
                "            name=\"unpack_binary_representation\",\n",
                "            expression=\"2*unpack_bits(attribute(binary_vector)) -1\",\n",
                "        )\n",
                "    ],\n",
                "    first_phase=FirstPhaseRanking(\n",
                "        expression=\"closeness(field, binary_vector)\"  # 1/(1 + hamming_distance). Calculated between the binary query and the binary_vector\n",
                "    ),\n",
                "    second_phase=SecondPhaseRanking(\n",
                "        expression=\"sum( query(q_full)* unpack_binary_representation )\",  # re-rank using the dot product between float query and the unpacked binary representation\n",
                "        rerank_count=100,\n",
                "    ),\n",
                "    match_features=[\"distance(field, binary_vector)\"],\n",
                ")\n",
                "my_schema.add_rank_profile(rerank)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c46c95aa",
            "metadata": {
                "id": "846545f9"
            },
            "source": [
                "## Deploy the application to Vespa Cloud\n",
                "\n",
                "With the configured application, we can deploy it to [Vespa Cloud](https://cloud.vespa.ai/en/).\n",
                "\n",
                "To deploy the application to Vespa Cloud we need to create a tenant in the Vespa Cloud:\n",
                "\n",
                "Create a tenant at [console.vespa-cloud.com](https://console.vespa-cloud.com/) (unless you already have one).\n",
                "This step requires a Google or GitHub account, and will start your [free trial](https://cloud.vespa.ai/en/free-trial).\n",
                "\n",
                "Make note of the tenant name, it is used in the next steps.\n",
                "\n",
                "> Note: Deployments to dev and perf expire after 7 days of inactivity, i.e., 7 days after running deploy. This applies to all plans, not only the Free Trial. Use the Vespa Console to extend the expiry period, or redeploy the application to add 7 more days.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "id": "3a11f211",
            "metadata": {
                "executionInfo": {
                    "elapsed": 339,
                    "status": "ok",
                    "timestamp": 1706652019048,
                    "user": {
                        "displayName": "Andreas Eriksen",
                        "userId": "00161553861396505040"
                    },
                    "user_tz": -60
                },
                "id": "b5fddf9f"
            },
            "outputs": [],
            "source": [
                "from vespa.deployment import VespaCloud\n",
                "import os\n",
                "\n",
                "# Replace with your tenant name from the Vespa Cloud Console\n",
                "tenant_name = \"vespa-team\"\n",
                "\n",
                "# Key is only used for CI/CD. Can be removed if logging in interactively\n",
                "key = os.getenv(\"VESPA_TEAM_API_KEY\", None)\n",
                "if key is not None:\n",
                "    key = key.replace(r\"\\n\", \"\\n\")  # To parse key correctly\n",
                "\n",
                "vespa_cloud = VespaCloud(\n",
                "    tenant=tenant_name,\n",
                "    application=vespa_app_name,\n",
                "    key_content=key,  # Key is only used for CI/CD. Can be removed if logging in interactively\n",
                "    application_package=vespa_application_package,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cc1c140a",
            "metadata": {
                "id": "fa9baa5a"
            },
            "source": [
                "Now deploy the app to Vespa Cloud dev zone.\n",
                "\n",
                "The first deployment typically takes 2 minutes until the endpoint is up.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "id": "494f5144",
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 12057,
                    "status": "ok",
                    "timestamp": 1706652033883,
                    "user": {
                        "displayName": "Andreas Eriksen",
                        "userId": "00161553861396505040"
                    },
                    "user_tz": -60
                },
                "id": "fe954dc4",
                "outputId": "6150363c-cfac-4240-e790-f84f98c481b0"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Deployment started in run 1 of dev-aws-us-east-1c for samples.mixedbreadai. This may take a few minutes the first time.\n",
                        "INFO    [22:14:39]  Deploying platform version 8.322.22 and application dev build 1 for dev-aws-us-east-1c of default ...\n",
                        "INFO    [22:14:39]  Using CA signed certificate version 0\n",
                        "INFO    [22:14:46]  Using 1 nodes in container cluster 'mixedbreadai_container'\n",
                        "INFO    [22:15:18]  Session 2205 for tenant 'samples' prepared and activated.\n",
                        "INFO    [22:15:21]  ######## Details for all nodes ########\n",
                        "INFO    [22:15:35]  h90193a.dev.aws-us-east-1c.vespa-external.aws.oath.cloud: expected to be UP\n",
                        "INFO    [22:15:35]  --- platform vespa/cloud-tenant-rhel8:8.322.22 <-- :\n",
                        "INFO    [22:15:35]  --- logserver-container on port 4080 has not started \n",
                        "INFO    [22:15:35]  --- metricsproxy-container on port 19092 has not started \n",
                        "INFO    [22:15:35]  h90971b.dev.aws-us-east-1c.vespa-external.aws.oath.cloud: expected to be UP\n",
                        "INFO    [22:15:35]  --- platform vespa/cloud-tenant-rhel8:8.322.22 <-- :\n",
                        "INFO    [22:15:35]  --- container-clustercontroller on port 19050 has not started \n",
                        "INFO    [22:15:35]  --- metricsproxy-container on port 19092 has not started \n",
                        "INFO    [22:15:35]  h91168a.dev.aws-us-east-1c.vespa-external.aws.oath.cloud: expected to be UP\n",
                        "INFO    [22:15:35]  --- platform vespa/cloud-tenant-rhel8:8.322.22 <-- :\n",
                        "INFO    [22:15:35]  --- storagenode on port 19102 has not started \n",
                        "INFO    [22:15:35]  --- searchnode on port 19107 has not started \n",
                        "INFO    [22:15:35]  --- distributor on port 19111 has not started \n",
                        "INFO    [22:15:35]  --- metricsproxy-container on port 19092 has not started \n",
                        "INFO    [22:15:35]  h91567a.dev.aws-us-east-1c.vespa-external.aws.oath.cloud: expected to be UP\n",
                        "INFO    [22:15:35]  --- platform vespa/cloud-tenant-rhel8:8.322.22 <-- :\n",
                        "INFO    [22:15:35]  --- container on port 4080 has not started \n",
                        "INFO    [22:15:35]  --- metricsproxy-container on port 19092 has not started \n",
                        "INFO    [22:16:41]  Waiting for convergence of 10 services across 4 nodes\n",
                        "INFO    [22:16:41]  1/1 nodes upgrading platform\n",
                        "INFO    [22:16:41]  2 application services still deploying\n",
                        "DEBUG   [22:16:41]  h91567a.dev.aws-us-east-1c.vespa-external.aws.oath.cloud: expected to be UP\n",
                        "DEBUG   [22:16:41]  --- platform vespa/cloud-tenant-rhel8:8.322.22 <-- :\n",
                        "DEBUG   [22:16:41]  --- container on port 4080 has not started \n",
                        "DEBUG   [22:16:41]  --- metricsproxy-container on port 19092 has not started \n",
                        "INFO    [22:17:11]  Found endpoints:\n",
                        "INFO    [22:17:11]  - dev.aws-us-east-1c\n",
                        "INFO    [22:17:11]   |-- https://cf949f23.b8a7f611.z.vespa-app.cloud/ (cluster 'mixedbreadai_container')\n",
                        "INFO    [22:17:12]  Installation succeeded!\n",
                        "Using mTLS (key,cert) Authentication against endpoint https://cf949f23.b8a7f611.z.vespa-app.cloud//ApplicationStatus\n",
                        "Application is up!\n",
                        "Finished deployment.\n"
                    ]
                }
            ],
            "source": [
                "from vespa.application import Vespa\n",
                "\n",
                "app: Vespa = vespa_cloud.deploy()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "abc3be8f",
            "metadata": {
                "id": "54db44b1"
            },
            "source": [
                "## Feed our sample documents and their binary embedding representation\n",
                "\n",
                "With few documents, we use the synchronous API. Read more in [reads and writes](https://pyvespa.readthedocs.io/en/latest/reads-writes.html).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "id": "00aad720",
            "metadata": {},
            "outputs": [],
            "source": [
                "from vespa.io import VespaResponse\n",
                "\n",
                "for i, doc in enumerate(documents):\n",
                "    response: VespaResponse = app.feed_data_point(\n",
                "        schema=\"doc\",\n",
                "        data_id=str(i),\n",
                "        fields={\n",
                "            \"doc_id\": str(i),\n",
                "            \"text\": doc,\n",
                "            \"binary_vector\": binary_embeddings[i].tolist(),\n",
                "        },\n",
                "    )\n",
                "    assert response.is_successful()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c39b1f1a",
            "metadata": {
                "id": "20b007ec"
            },
            "source": [
                "### Querying data\n",
                "\n",
                "Read more about querying Vespa in:\n",
                "\n",
                "- [Vespa Query API](https://docs.vespa.ai/en/query-api.html)\n",
                "- [Vespa Query API reference](https://docs.vespa.ai/en/reference/query-api-reference.html)\n",
                "- [Vespa Query Language API (YQL)](https://docs.vespa.ai/en/query-language.html)\n",
                "- [Practical Nearest Neighbor Search Guide](https://docs.vespa.ai/en/nearest-neighbor-search-guide.html)\n",
                "\n",
                "In this case, we use [quantization.quantize_embeddings](https://sbert.net/docs/package_reference/quantization.html#sentence_transformers.quantization.quantize_embeddings)\n",
                "after first obtaining the float version, this to avoid running the model inference twice.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 54,
            "id": "377da3d7",
            "metadata": {},
            "outputs": [],
            "source": [
                "query = \"Who was Isac Newton?\"\n",
                "# This returns the float version\n",
                "query_embedding_float = model.encode([query])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cb77d398",
            "metadata": {},
            "outputs": [],
            "source": [
                "from sentence_transformers.quantization import quantize_embeddings\n",
                "\n",
                "query_embedding_binary = quantize_embeddings(query_embedding_float, precision=\"binary\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2d086ade",
            "metadata": {},
            "source": [
                "Now, we use nearestNeighbor search to retrieve 100 hits (`targetHits`) using the configured distance-metric (hamming distance). The retrieved hits are exposed to the ‹espa ranking framework, where we re-rank\n",
                "using the dot product between the float tensor and the unpacked binary vector.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 55,
            "id": "686f1cf0",
            "metadata": {},
            "outputs": [],
            "source": [
                "response = app.query(\n",
                "    yql=\"select * from doc where {targetHits:100}nearestNeighbor(binary_vector,q_binary)\",\n",
                "    ranking=\"rerank\",\n",
                "    body={\n",
                "        \"input.query(q_binary)\": query_embedding_binary[0].tolist(),\n",
                "        \"input.query(q_full)\": query_embedding_float[0].tolist(),\n",
                "    },\n",
                ")\n",
                "assert response.is_successful()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 56,
            "id": "7f84d4c6",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[\n",
                        "  {\n",
                        "    \"id\": \"id:doc:doc::2\",\n",
                        "    \"relevance\": 177.8957977294922,\n",
                        "    \"source\": \"mixedbreadai_content\",\n",
                        "    \"fields\": {\n",
                        "      \"matchfeatures\": {\n",
                        "        \"closeness(field,binary_vector)\": 0.003484320557491289,\n",
                        "        \"distance(field,binary_vector)\": 286.0\n",
                        "      },\n",
                        "      \"sddocname\": \"doc\",\n",
                        "      \"documentid\": \"id:doc:doc::2\",\n",
                        "      \"doc_id\": \"2\",\n",
                        "      \"text\": \"Isaac Newton was an English polymath active as a mathematician, physicist, astronomer, alchemist, theologian, and author who was described in his time as a natural philosopher.\"\n",
                        "    }\n",
                        "  },\n",
                        "  {\n",
                        "    \"id\": \"id:doc:doc::1\",\n",
                        "    \"relevance\": 144.52731323242188,\n",
                        "    \"source\": \"mixedbreadai_content\",\n",
                        "    \"fields\": {\n",
                        "      \"matchfeatures\": {\n",
                        "        \"closeness(field,binary_vector)\": 0.002890173410404624,\n",
                        "        \"distance(field,binary_vector)\": 345.0\n",
                        "      },\n",
                        "      \"sddocname\": \"doc\",\n",
                        "      \"documentid\": \"id:doc:doc::1\",\n",
                        "      \"doc_id\": \"1\",\n",
                        "      \"text\": \"Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time.\"\n",
                        "    }\n",
                        "  },\n",
                        "  {\n",
                        "    \"id\": \"id:doc:doc::0\",\n",
                        "    \"relevance\": 138.78799438476562,\n",
                        "    \"source\": \"mixedbreadai_content\",\n",
                        "    \"fields\": {\n",
                        "      \"matchfeatures\": {\n",
                        "        \"closeness(field,binary_vector)\": 0.00273224043715847,\n",
                        "        \"distance(field,binary_vector)\": 365.0\n",
                        "      },\n",
                        "      \"sddocname\": \"doc\",\n",
                        "      \"documentid\": \"id:doc:doc::0\",\n",
                        "      \"doc_id\": \"0\",\n",
                        "      \"text\": \"Alan Turing  was an English mathematician, computer scientist, logician, cryptanalyst, philosopher and theoretical biologist.\"\n",
                        "    }\n",
                        "  },\n",
                        "  {\n",
                        "    \"id\": \"id:doc:doc::3\",\n",
                        "    \"relevance\": 115.2405776977539,\n",
                        "    \"source\": \"mixedbreadai_content\",\n",
                        "    \"fields\": {\n",
                        "      \"matchfeatures\": {\n",
                        "        \"closeness(field,binary_vector)\": 0.002652519893899204,\n",
                        "        \"distance(field,binary_vector)\": 376.0\n",
                        "      },\n",
                        "      \"sddocname\": \"doc\",\n",
                        "      \"documentid\": \"id:doc:doc::3\",\n",
                        "      \"doc_id\": \"3\",\n",
                        "      \"text\": \"Marie Curie was a Polish and naturalised-French physicist and chemist who conducted pioneering research on radioactivity\"\n",
                        "    }\n",
                        "  }\n",
                        "]\n"
                    ]
                }
            ],
            "source": [
                "import json\n",
                "\n",
                "print(json.dumps(response.hits, indent=2))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9b9f45d3",
            "metadata": {
                "id": "7c8b8223"
            },
            "source": [
                "## Summary\n",
                "\n",
                "Binary embeddings is an exciting development, as it reduces storage (32) and speed up vector searches as the hamming distance is much\n",
                "more efficient than distance metrics like angular or euclidean.\n",
                "\n",
                "### Clean up\n",
                "\n",
                "We can now delete the cloud instance:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7fb27b941602401d91542211134fc71a",
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 3720,
                    "status": "ok",
                    "timestamp": 1705505103257,
                    "user": {
                        "displayName": "Andreas Eriksen",
                        "userId": "00161553861396505040"
                    },
                    "user_tz": -60
                },
                "id": "71e310e3",
                "outputId": "991b1965-6c33-4985-e873-a92c43695528"
            },
            "outputs": [],
            "source": [
                "vespa_cloud.delete()"
            ]
        }
    ],
    "metadata": {
        "colab": {
            "name": "",
            "provenance": [
                {
                    "file_id": "1FoVAybR6dhXy-uDkVuDfBtVzSJoresCB",
                    "timestamp": 1706644027750
                }
            ],
            "version": ""
        },
        "kernelspec": {
            "display_name": "Python 3.11.4 64-bit",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        },
        "vscode": {
            "interpreter": {
                "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}