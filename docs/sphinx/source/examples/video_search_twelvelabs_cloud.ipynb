{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "BXfYSnoaYyl4",
   "metadata": {
    "id": "BXfYSnoaYyl4"
   },
   "source": [
    "<picture>\n",
    "  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://assets.vespa.ai/logos/Vespa-logo-green-RGB.svg\">\n",
    "  <source media=\"(prefers-color-scheme: light)\" srcset=\"https://assets.vespa.ai/logos/Vespa-logo-dark-RGB.svg\">\n",
    "  <img alt=\"#Vespa\" width=\"200\" src=\"https://assets.vespa.ai/logos/Vespa-logo-dark-RGB.svg\" style=\"margin-bottom: 25px;\">\n",
    "</picture>\n",
    "\n",
    "\n",
    "# Video Search and Retrieval with Vespa and TwelveLabs\n",
    "\n",
    "In the following notebook, we will demonstrate how to leverage [TwelveLabs](https://www.twelvelabs.io/) `Marengo-retrieval-2.7` a SOTA multimodal embedding model to demonstrate a use case of video embeddings storage and semantic search retrieval using Vespa.ai.\n",
    "\n",
    "The steps we will take in this notebook are:\n",
    "\n",
    "1. Setup and configuration\n",
    "2. Generate Attributes and Embeddings for 3 sample videos using the TwelveLabs python SDK.\n",
    "3. Deploy the Vespa application to Vespa Cloud and Feed the Data\n",
    "4. Perform a semantic search with hybrid multi-phase ranking on the videos\n",
    "5. Review the results\n",
    "6. Cleanup\n",
    "\n",
    "All the steps that are needed to provision the Vespa application, including feeding the data, can be done by running this notebook.\n",
    "We have tried to make it easy for others to run this notebook, to create your own Video semantic search application using TwelveLabs models with Vespa.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vespa-engine/pyvespa/blob/master/docs/sphinx/source/examples/video_search_twelvelabs_cloud.ipynb)\n",
    "\n",
    "## 1. Setup and Configuration\n",
    "\n",
    "For reference, this is the Python version used for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "C2muzvA8yyXFRL7zrDpEgpmJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C2muzvA8yyXFRL7zrDpEgpmJ",
    "outputId": "baabbc0a-4a93-4795-e36a-152030b6e287",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.4\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NPWxNjsXa5vd",
   "metadata": {
    "id": "NPWxNjsXa5vd"
   },
   "source": [
    "### 1.1 Install libraries\n",
    "\n",
    "Install the required Python dependencies from TwelveLabs python SDK and pyvespa python API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "OzBunhAMSMUF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OzBunhAMSMUF",
    "outputId": "ee27446c-d85d-4aea-b8c0-b570fe7bf025"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyvespa in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (0.55.0)\n",
      "Requirement already satisfied: vespacli in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (8.391.23)\n",
      "Requirement already satisfied: twelvelabs in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (0.4.10)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from pyvespa) (2.32.3)\n",
      "Requirement already satisfied: requests_toolbelt in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from pyvespa) (1.0.0)\n",
      "Requirement already satisfied: docker in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from pyvespa) (7.1.0)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from pyvespa) (3.1.4)\n",
      "Requirement already satisfied: cryptography in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from pyvespa) (43.0.3)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from pyvespa) (3.10.10)\n",
      "Requirement already satisfied: httpx[http2] in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from pyvespa) (0.28.1)\n",
      "Requirement already satisfied: tenacity>=8.4.1 in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from pyvespa) (9.0.0)\n",
      "Requirement already satisfied: typing_extensions in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from pyvespa) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from pyvespa) (2.9.0.post0)\n",
      "Requirement already satisfied: fastcore>=1.7.8 in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from pyvespa) (1.7.19)\n",
      "Requirement already satisfied: lxml in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from pyvespa) (5.3.0)\n",
      "Requirement already satisfied: pydantic>=2.4.2 in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from twelvelabs) (2.10.6)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from fastcore>=1.7.8->pyvespa) (24.2)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from httpx[http2]->pyvespa) (4.8.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from httpx[http2]->pyvespa) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from httpx[http2]->pyvespa) (1.0.7)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from httpx[http2]->pyvespa) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from httpcore==1.*->httpx[http2]->pyvespa) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from pydantic>=2.4.2->twelvelabs) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from pydantic>=2.4.2->twelvelabs) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from python-dateutil->pyvespa) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from aiohttp->pyvespa) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from aiohttp->pyvespa) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from aiohttp->pyvespa) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from aiohttp->pyvespa) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from aiohttp->pyvespa) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from aiohttp->pyvespa) (1.15.5)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from cryptography->pyvespa) (1.17.1)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from docker->pyvespa) (2.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from requests->pyvespa) (3.4.1)\n",
      "Requirement already satisfied: h2<5,>=3 in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from httpx[http2]->pyvespa) (4.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from jinja2->pyvespa) (3.0.2)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from cffi>=1.12->cryptography->pyvespa) (2.22)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from h2<5,>=3->httpx[http2]->pyvespa) (6.0.1)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from h2<5,>=3->httpx[http2]->pyvespa) (4.0.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from yarl<2.0,>=1.12.0->aiohttp->pyvespa) (0.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/envs/vespa-env/lib/python3.12/site-packages (from anyio->httpx[http2]->pyvespa) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pyvespa vespacli twelvelabs pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8veAJGipbjVA",
   "metadata": {
    "id": "8veAJGipbjVA"
   },
   "source": [
    "Import all the required packages in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "Ojdxaw85h9tV",
   "metadata": {
    "id": "Ojdxaw85h9tV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import json\n",
    "\n",
    "from vespa.package import (\n",
    "    ApplicationPackage,\n",
    "    Field,\n",
    "    Schema,\n",
    "    Document,\n",
    "    HNSW,\n",
    "    RankProfile,\n",
    "    FieldSet,\n",
    "    SecondPhaseRanking,\n",
    "    Function,\n",
    ")\n",
    "\n",
    "from vespa.deployment import VespaCloud\n",
    "from vespa.io import VespaResponse, VespaQueryResponse\n",
    "\n",
    "from twelvelabs import TwelveLabs\n",
    "from twelvelabs.models.embed import EmbeddingsTask\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ukp_0PzHXAf-",
   "metadata": {
    "id": "Ukp_0PzHXAf-"
   },
   "source": [
    "### 1.2 Get a TwelveLabs API key\n",
    "[Sign-up](https://auth.twelvelabs.io/u/signup) for TwelveLabs.\n",
    "\n",
    "After logging in, navigate to your profile and get your [API key](https://playground.twelvelabs.io/dashboard/api-key). Copy it and paste it below.\n",
    "\n",
    "The Free plan includes indexing of 600 mins of videos, which should be sufficient to explore the capabilities of the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e381016",
   "metadata": {
    "id": "7e381016"
   },
   "outputs": [],
   "source": [
    "TL_API_KEY = os.getenv(\"TL_API_KEY\") or input(\"Enter your TL_API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AfCgIhMPXnQQ",
   "metadata": {
    "id": "AfCgIhMPXnQQ"
   },
   "source": [
    "### 1.3 Sign-up for a Vespa Trial Account\n",
    "\n",
    "**Pre-requisite**:\n",
    "- Spin-up a Vespa Cloud [Trial](https://vespa.ai/free-trial) account.\n",
    "- Login to the account you just created and create a tenant at [console.vespa-cloud.com](https://console.vespa-cloud.com/).\n",
    "- Save the tenant name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "B7uKLKsrYQgT",
   "metadata": {
    "id": "B7uKLKsrYQgT"
   },
   "source": [
    "### 1.4 Setup the tenant name and the application name\n",
    "\n",
    "- Paste below the name of the tenant name.\n",
    "- Give your application a name. Note that the name cannot have `-` or `_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zJlBCg6ahzJM",
   "metadata": {
    "id": "zJlBCg6ahzJM"
   },
   "outputs": [],
   "source": [
    "# Replace with your tenant name from the Vespa Cloud Console\n",
    "tenant_name = \"vespa-team\"\n",
    "# Replace with your application name (does not need to exist yet)\n",
    "application = \"videosearch\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ga0DUN47dLjK",
   "metadata": {
    "id": "Ga0DUN47dLjK"
   },
   "source": [
    "## 2. Generate Attributes and Embeddings for sample videos using TwelveLabs Embedding API\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7jXol6MHVy1i",
   "metadata": {
    "id": "7jXol6MHVy1i"
   },
   "source": [
    "### 2.1 Generate attributes on the videos\n",
    "\n",
    "In this section, we will leverage the [Pegasus 1.2](https://docs.twelvelabs.io/v1.3/docs/concepts/models/pegasus) generative model to generate some attributes about our videos to store as part of the searchable information in Vespa. Attributes we want to store as part of the videos include:\n",
    "\n",
    "- Keywords\n",
    "- Summaries\n",
    "\n",
    "For video samples, we are selecting the 3 videos in the array below from the [Internet Archive](https://archive.org/).\n",
    "\n",
    "You can customize this code with the urls of your choice. Note that there are certain restrictions such as the resolution of the videos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eQkLI-moZPhL",
   "metadata": {
    "id": "eQkLI-moZPhL"
   },
   "outputs": [],
   "source": [
    "VIDEO_URLs = [\n",
    "    \"https://archive.org/download/the-end-blue-sky-studios/The%20End%281080P_60FPS%29.ia.mp4\",\n",
    "    \"https://ia601401.us.archive.org/1/items/twas-the-night-before-christmas-1974-full-movie-freedownloadvideo.net/twas-the-night-before-christmas-1974-full-movie-freedownloadvideo.net.mp4\",\n",
    "    \"https://archive.org/download/The_Worm_in_the_Apple_Animation_Test/AnimationTest.mov\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yZa-YDeNZ63r",
   "metadata": {
    "id": "yZa-YDeNZ63r"
   },
   "source": [
    "In order to generate text on the videos, the prerequisite is to upload the videos and index them. Let's first create an index below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "elAj0cm1Upaa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "elAj0cm1Upaa",
    "outputId": "42441224-3947-4d32-cf2a-2c33b0d0da4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Index:Vespa_1752595622\n",
      "Created index: id=68767ca6e01b53f51c3f2ac5 name=Vespa_1752595622 models=root=[Model(name='pegasus1.2', options=['visual', 'audio'], addons=None, finetuned=False)]\n"
     ]
    }
   ],
   "source": [
    "# Spin-up session\n",
    "client = TwelveLabs(api_key=TL_API_KEY)\n",
    "\n",
    "# Generating Index Name\n",
    "timestamp = int(datetime.now().timestamp())\n",
    "index_name = \"Vespa_\" + str(timestamp)\n",
    "\n",
    "# Create Index\n",
    "print(\"Creating Index:\" + index_name)\n",
    "index = client.index.create(\n",
    "    name=index_name,\n",
    "    models=[\n",
    "        {\n",
    "            \"name\": \"pegasus1.2\",\n",
    "            \"options\": [\"visual\", \"audio\"],\n",
    "        }\n",
    "    ],\n",
    "    addons=[\"thumbnail\"],  # Optional\n",
    ")\n",
    "print(f\"Created index: id={index.id} name={index.name} models={index.models}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ylbZo766ayig",
   "metadata": {
    "id": "ylbZo766ayig"
   },
   "source": [
    "We can now upload the videos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "oEKeONmX7ffB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oEKeONmX7ffB",
    "outputId": "23cd7603-5bbf-4ca3-eb3d-6f901e1ba767"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task created successfully! Task ID: 68767caa47c93cd3ab1e4b05\n",
      "  Status=pending\n",
      "  Status=pending\n",
      "  Status=pending\n",
      "  Status=pending\n",
      "  Status=ready\n",
      "Indexing done: Task(id='68767caa47c93cd3ab1e4b05', created_at='2025-07-15T16:07:08.998Z', updated_at='2025-07-15T16:07:08.998Z', index_id='68767ca6e01b53f51c3f2ac5', video_id='68767caa47c93cd3ab1e4b05', status='ready', system_metadata={'filename': 'The End(1080P_60FPS).ia.mp4', 'duration': 34.667392, 'width': 1920, 'height': 1080}, hls=TaskHLS(video_url='', thumbnail_urls=[], status='PROCESSING', updated_at='2025-07-15T16:07:08.998Z'))\n",
      "Uploaded https://archive.org/download/the-end-blue-sky-studios/The%20End%281080P_60FPS%29.ia.mp4. The unique identifer of your video is 68767caa47c93cd3ab1e4b05.\n",
      "Task created successfully! Task ID: 68767ce06c4253f85f0820d0\n",
      "  Status=indexing\n",
      "  Status=indexing\n",
      "  Status=indexing\n",
      "  Status=indexing\n",
      "  Status=indexing\n",
      "  Status=indexing\n",
      "  Status=indexing\n",
      "  Status=indexing\n",
      "  Status=indexing\n",
      "  Status=indexing\n",
      "  Status=indexing\n",
      "  Status=indexing\n",
      "  Status=indexing\n",
      "  Status=indexing\n",
      "  Status=ready\n",
      "Indexing done: Task(id='68767ce06c4253f85f0820d0', created_at='2025-07-15T16:08:01.059Z', updated_at='2025-07-15T16:08:01.059Z', index_id='68767ca6e01b53f51c3f2ac5', video_id='68767ce06c4253f85f0820d0', status='ready', system_metadata={'filename': 'twas-the-night-before-christmas-1974-full-movie-freedownloadvideo.net.mp4', 'duration': 1448.88, 'width': 640, 'height': 480}, hls=TaskHLS(video_url='', thumbnail_urls=[], status='PROCESSING', updated_at='2025-07-15T16:08:01.059Z'))\n",
      "Uploaded https://ia601401.us.archive.org/1/items/twas-the-night-before-christmas-1974-full-movie-freedownloadvideo.net/twas-the-night-before-christmas-1974-full-movie-freedownloadvideo.net.mp4. The unique identifer of your video is 68767ce06c4253f85f0820d0.\n",
      "Task created successfully! Task ID: 68767d7a03f1a1f6cd14797d\n",
      "  Status=pending\n",
      "  Status=indexing\n",
      "  Status=ready\n",
      "Indexing done: Task(id='68767d7a03f1a1f6cd14797d', created_at='2025-07-15T16:10:37.601Z', updated_at='2025-07-15T16:10:37.601Z', index_id='68767ca6e01b53f51c3f2ac5', video_id='68767d7a03f1a1f6cd14797d', status='ready', system_metadata={'filename': 'AnimationTest.mov', 'duration': 24.45679, 'width': 720, 'height': 405}, hls=TaskHLS(video_url='', thumbnail_urls=[], status='PROCESSING', updated_at='2025-07-15T16:10:37.601Z'))\n",
      "Uploaded https://archive.org/download/The_Worm_in_the_Apple_Animation_Test/AnimationTest.mov. The unique identifer of your video is 68767d7a03f1a1f6cd14797d.\n"
     ]
    }
   ],
   "source": [
    "# Capturing index id for upload\n",
    "index_id = index.id\n",
    "\n",
    "def on_task_update(task: EmbeddingsTask):\n",
    "    print(f\"  Status={task.status}\")\n",
    "\n",
    "\n",
    "for video_url in VIDEO_URLs:\n",
    "    # Create a video indexing task\n",
    "    task = client.task.create(index_id=index_id, url=video_url)\n",
    "    print(f\"Task created successfully! Task ID: {task.id}\")\n",
    "    status = task.wait_for_done(sleep_interval=10, callback=on_task_update)\n",
    "    print(f\"Indexing done: {status}\")\n",
    "    if task.status != \"ready\":\n",
    "        raise RuntimeError(f\"Indexing failed with status {task.status}\")\n",
    "    print(\n",
    "        f\"Uploaded {video_url}. The unique identifer of your video is {task.video_id}.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yakP4RZabFxR",
   "metadata": {
    "id": "yakP4RZabFxR"
   },
   "source": [
    "Now that the videos have been uploaded, we can generate the keywords, and summaries on the videos below. You will notice on the output that the video uploaded last is the one that is processed first in this stage. This matters since we store other attributes on the videos on arrays (eg URLs, Titles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "z0m24cYj9-FC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z0m24cYj9-FC",
    "outputId": "c5115b41-f406-4131-cca6-733715c71ff8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating text for 68767d7a03f1a1f6cd14797d\n",
      "Summary:\n",
      "The video titled \"The Worm in the Apple Animation Test\" showcases a whimsical scene where a segmented worm\n",
      "emerges from a red apple, positioned on the left side of the frame, and moves across a green field under a\n",
      "cloudy sky. As the worm progresses, its segments detach one by one, leaving the head connected to the last\n",
      "segment, with the detached parts scattered around the base of the hill where the apple rests. The camera zooms\n",
      "out to reveal more of the grassy terrain and then focuses closely on the worm's face, which exhibits a range\n",
      "of expressions from surprise to anger, enhancing the animated narrative. The worm's journey ends as it crawls\n",
      "off-screen, leaving behind a visually engaging and animated sequence. The video is accompanied by a\n",
      "repetitive, light-hearted musical score that adds to the playful tone of the animation.\n",
      "Open-ended Text: worm, apple, animation, test, victor lyuboslavsky\n",
      "Generating text for 68767ce06c4253f85f0820d0\n",
      "Summary:\n",
      "The video is an animated adaptation of \"Twas The Night Before Christmas,\" featuring a blend of human and mouse\n",
      "characters. It begins with a snowy night scene and transitions to a clockmaker's workshop, where the\n",
      "clockmaker, Joshua Trundle, and his family face challenges after a critical letter to Santa is written by\n",
      "Albert, Trundle's son. The story unfolds with the town's efforts to reconcile with Santa through a special\n",
      "clock designed to play a welcoming song on Christmas Eve, but complications arise when the clock malfunctions.\n",
      "Despite the setbacks, the family and community work together to fix the clock and restore belief in Santa,\n",
      "culminating in his magical arrival, bringing joy and gifts to all. The video concludes with a heartfelt\n",
      "message about the power of belief and the importance of making amends.\n",
      "Open-ended Text: snowy village, clock tower, Santa Claus, mechanical gears, Christmas chimes\n",
      "Generating text for 68767caa47c93cd3ab1e4b05\n",
      "Summary:\n",
      "The video captures a serene snowy landscape with pine trees under a cloudy sky, where a squirrel emerges from\n",
      "behind a rock formation carrying an acorn. Upon noticing another acorn in the foreground, the squirrel appears\n",
      "momentarily surprised, as indicated by its vocalization \"Oh...\". It then drops one acorn and begins to nibble\n",
      "on the other, eventually discarding fragments of it before leaping away. The scene concludes with the\n",
      "squirrel's departure, leaving behind the remnants of the acorn, as darkness gradually engulfs the snowy\n",
      "setting.\n",
      "Open-ended Text: squirrel, acorn, winter, snow, forest\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "client = TwelveLabs(api_key=TL_API_KEY)\n",
    "\n",
    "\n",
    "summaries = []\n",
    "keywords_array = []\n",
    "\n",
    "# Get all videos in an Index\n",
    "videos = client.index.video.list(index_id)\n",
    "for video in videos:\n",
    "    print(f\"Generating text for {video.id}\")\n",
    "\n",
    "    res = client.summarize(\n",
    "        video_id=video.id,\n",
    "        type=\"summary\",\n",
    "        prompt=\"Generate an abstract of the video serving as metadata on the video, up to five sentences.\",\n",
    "    )\n",
    "    \n",
    "    wrapped = textwrap.wrap(res.summary, width=110)\n",
    "    print(\"Summary:\")\n",
    "    print(\"\\n\".join(wrapped))\n",
    "    summaries.append(res.summary)\n",
    "\n",
    "    keywords = client.analyze(\n",
    "        video_id=video.id,\n",
    "        prompt=\"Based on this video, I want to generate five keywords for SEO (Search Engine Optimization). Provide just the keywords as a comma delimited list without any additional text.\",\n",
    "    )\n",
    "    print(f\"Open-ended Text: {keywords.data}\")\n",
    "    keywords_array.append(keywords.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VBebeBFcc7vx",
   "metadata": {
    "id": "VBebeBFcc7vx"
   },
   "source": [
    "We need to store the titles of the videos as an additional attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "sPliZOSZU3em",
   "metadata": {
    "id": "sPliZOSZU3em"
   },
   "outputs": [],
   "source": [
    "# Creating array with titles\n",
    "titles = [\n",
    "    \"The Worm in the Apple Animation Test\",\n",
    "    \"Twas the night before Christmas\",\n",
    "    \"The END (Blue Sky Studios)\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aJ2Rr5fDD8",
   "metadata": {
    "id": "c4aJ2Rr5fDD8"
   },
   "source": [
    "## 2.2 Generate Embeddings\n",
    "\n",
    "The following code leverages the [Embed API](https://docs.twelvelabs.io/docs/create-video-embeddings) to create an asynchronous embedding task to embed the sample videos.\n",
    "\n",
    "Twelve Labs video embeddings capture all the subtle cues and interactions between different modalities, including the visual expressions, body language, spoken words, and the overall context of the video, encapsulating the essence of all these modalities and their interrelations over time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "qm2DXkatR1pP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qm2DXkatR1pP",
    "outputId": "f386fc9d-c41f-4626-ca0c-4f283a147aca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created task: id=6876856e4fc16ea9b2fdb823 model_name=Marengo-retrieval-2.7 status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=ready\n",
      "Embedding done: ready\n",
      "Created task: id=68768593de7e2a0235058cc6 model_name=Marengo-retrieval-2.7 status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=ready\n",
      "Embedding done: ready\n",
      "Created task: id=6876860547c93cd3ab1e4cd7 model_name=Marengo-retrieval-2.7 status=processing\n",
      "  Status=processing\n",
      "  Status=ready\n",
      "Embedding done: ready\n"
     ]
    }
   ],
   "source": [
    "client = TwelveLabs(api_key=TL_API_KEY)\n",
    "\n",
    "# Initialize an array to store the task IDs as strings\n",
    "task_ids = []\n",
    "\n",
    "for url in VIDEO_URLs:\n",
    "    task = client.embed.task.create(model_name=\"Marengo-retrieval-2.7\", video_url=url)\n",
    "    print(\n",
    "        f\"Created task: id={task.id} model_name={task.model_name} status={task.status}\"\n",
    "    )\n",
    "    # Append the task ID to the array\n",
    "    task_ids.append(str(task.id))\n",
    "    status = task.wait_for_done(sleep_interval=10, callback=on_task_update)\n",
    "    print(f\"Embedding done: {status}\")\n",
    "    if task.status != \"ready\":\n",
    "        raise RuntimeError(f\"Embedding failed with status {task.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6R198-KVq9if",
   "metadata": {
    "id": "6R198-KVq9if"
   },
   "source": [
    "## 2.3 Retrieve Embeddings\n",
    "\n",
    "Once the embedding task is completed, we can retrieve the results of the embedding task based on the task_ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9By4UdCgGChw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9By4UdCgGChw",
    "outputId": "2b1be60e-447a-4dc7-b0ea-28608c3808d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task ID: 6876856e4fc16ea9b2fdb823\n",
      "Status: ready\n",
      "Task ID: 68768593de7e2a0235058cc6\n",
      "Status: ready\n",
      "Task ID: 6876860547c93cd3ab1e4cd7\n",
      "Status: ready\n"
     ]
    }
   ],
   "source": [
    "# Spin-up session\n",
    "client = TwelveLabs(api_key=TL_API_KEY)\n",
    "\n",
    "# Initialize an array to store the task objects directly\n",
    "tasks = []\n",
    "\n",
    "for task_id in task_ids:\n",
    "    # Retrieve the task\n",
    "    task = client.embed.task.retrieve(task_id)\n",
    "    tasks.append(task)\n",
    "\n",
    "    # Print task details\n",
    "    print(f\"Task ID: {task.id}\")\n",
    "    print(f\"Status: {task.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kpuVxCshxoD3",
   "metadata": {
    "id": "kpuVxCshxoD3"
   },
   "source": [
    "We can now review the output structure of the first segment for each one of these videos. This output will help us define the schema to store the embeddings in Vespa in the second part of this notebook.\n",
    "\n",
    "From looking at this output, the video has been embedded into chunks of 6 seconds each (default configurable value in the Embed API). Each embedding has a float vector of dimension 1024.\n",
    "\n",
    "The number of segments generated vary per video, based on the length of the videos ranging from 37 to 242 segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4iyjmzpYsRUz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4iyjmzpYsRUz",
    "outputId": "242c5746-f198-42ec-f973-39933a9ce5ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6876856e4fc16ea9b2fdb823\n",
      "start_offset_sec: float : 0.0\n",
      "end_offset_sec: float : 6.0\n",
      "embedding_scope: str : clip\n",
      "embedding_option: str : visual-text\n",
      "embeddings_float: list of size 1024 (truncated to 5 items): [0.0227238, -0.002079417, 0.01519275, -0.009030234, -0.00162781] \n",
      "Total Number of segments: 12\n",
      "68768593de7e2a0235058cc6\n",
      "start_offset_sec: float : 0.0\n",
      "end_offset_sec: float : 6.0\n",
      "embedding_scope: str : clip\n",
      "embedding_option: str : visual-text\n",
      "embeddings_float: list of size 1024 (truncated to 5 items): [0.024328815, -0.0035867887, 0.016065866, 0.02501548, 0.007778642] \n",
      "Total Number of segments: 484\n",
      "6876860547c93cd3ab1e4cd7\n",
      "start_offset_sec: float : 0.0\n",
      "end_offset_sec: float : 6.0\n",
      "embedding_scope: str : clip\n",
      "embedding_option: str : visual-text\n",
      "embeddings_float: list of size 1024 (truncated to 5 items): [0.05419811, -0.0018933096, 0.008044507, -0.01940344, 0.013152712] \n",
      "Total Number of segments: 8\n"
     ]
    }
   ],
   "source": [
    "for task in tasks:\n",
    "    print(task.id)\n",
    "    # Display data types of each field\n",
    "    for key, value in task.video_embedding.segments[0]:\n",
    "        if isinstance(value, list):\n",
    "            print(\n",
    "                f\"{key}: list of size {len(value)} (truncated to 5 items): {value[:5]} \"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"{key}: {type(value).__name__} : {value}\")\n",
    "    print(f\"Total Number of segments: {len(task.video_embedding.segments)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1iscs7g-5xOD",
   "metadata": {
    "id": "1iscs7g-5xOD"
   },
   "source": [
    "# 3. Deploy a Vespa Application\n",
    "\n",
    "At this point, we are ready to deploy a Vespa Application. We have generated the attributes we needed on each video, as well as the embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hbZ-pJO37-1O",
   "metadata": {
    "id": "hbZ-pJO37-1O"
   },
   "source": [
    "## 3.1 Create an Application Package\n",
    "\n",
    "The [application package](https://vespa-engine.github.io/pyvespa/api/vespa/package.html)\n",
    "has all the Vespa configuration files -\n",
    "create one from scratch:\n",
    "\n",
    "The Vespa schema deployed as part of the package is called `videos`. All the fields are matching the output of the Twelvelabs Embed API above. Refer to the [Vespa documentation](https://docs.vespa.ai/en/reference/schema-reference.html) for more information on the schema specification.\n",
    "\n",
    "We can first define the schema using pyvespa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "T941tSJOiDCx",
   "metadata": {
    "id": "T941tSJOiDCx"
   },
   "outputs": [],
   "source": [
    "videos_schema = Schema(\n",
    "    name=\"videos\",\n",
    "    document=Document(\n",
    "        fields=[\n",
    "            Field(name=\"video_url\", type=\"string\", indexing=[\"summary\"]),\n",
    "            Field(\n",
    "                name=\"title\",\n",
    "                type=\"string\",\n",
    "                indexing=[\"index\", \"summary\"],\n",
    "                match=[\"text\"],\n",
    "                index=\"enable-bm25\",\n",
    "            ),\n",
    "            Field(\n",
    "                name=\"keywords\",\n",
    "                type=\"string\",\n",
    "                indexing=[\"index\", \"summary\"],\n",
    "                match=[\"text\"],\n",
    "                index=\"enable-bm25\",\n",
    "            ),\n",
    "            Field(\n",
    "                name=\"video_summary\",\n",
    "                type=\"string\",\n",
    "                indexing=[\"index\", \"summary\"],\n",
    "                match=[\"text\"],\n",
    "                index=\"enable-bm25\",\n",
    "            ),\n",
    "            Field(\n",
    "                name=\"embedding_scope\", type=\"string\", indexing=[\"attribute\", \"summary\"]\n",
    "            ),\n",
    "            Field(\n",
    "                name=\"start_offset_sec\",\n",
    "                type=\"array<float>\",\n",
    "                indexing=[\"attribute\", \"summary\"],\n",
    "            ),\n",
    "            Field(\n",
    "                name=\"end_offset_sec\",\n",
    "                type=\"array<float>\",\n",
    "                indexing=[\"attribute\", \"summary\"],\n",
    "            ),\n",
    "            Field(\n",
    "                name=\"embeddings\",\n",
    "                type=\"tensor<float>(p{},x[1024])\",\n",
    "                indexing=[\"index\", \"attribute\"],\n",
    "                ann=HNSW(distance_metric=\"angular\"),\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "fieldsets = (\n",
    "    [\n",
    "        FieldSet(\n",
    "            name=\"default\",\n",
    "            fields=[\"title\", \"keywords\", \"video_summary\"],\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "mapfunctions = [\n",
    "    Function(\n",
    "        name=\"similarities\",\n",
    "        expression=\"\"\"\n",
    "                      sum(\n",
    "                          query(q) * attribute(embeddings), x\n",
    "                          )\n",
    "                      \"\"\",\n",
    "    ),\n",
    "    Function(\n",
    "        name=\"bm25_score\",\n",
    "        expression=\"bm25(title) + bm25(keywords) + bm25(video_summary)\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "semantic_rankprofile = RankProfile(\n",
    "    name=\"hybrid\",\n",
    "    inputs=[(\"query(q)\", \"tensor<float>(x[1024])\")],\n",
    "    first_phase=\"bm25_score\",\n",
    "    second_phase=SecondPhaseRanking(\n",
    "        expression=\"closeness(field, embeddings)\", rerank_count=10\n",
    "    ),\n",
    "    match_features=[\"closest(embeddings)\"],\n",
    "    summary_features=[\"similarities\"],\n",
    "    functions=mapfunctions,\n",
    ")\n",
    "\n",
    "videos_schema.add_rank_profile(semantic_rankprofile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HsUrAY78k6Xr",
   "metadata": {
    "id": "HsUrAY78k6Xr"
   },
   "source": [
    "We can now create the package based on the previous schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "qvRl19JFBJGS",
   "metadata": {
    "id": "qvRl19JFBJGS"
   },
   "outputs": [],
   "source": [
    "# Create the Vespa application package\n",
    "package = ApplicationPackage(name=application, schema=[videos_schema])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_BJzOAOM_QFW",
   "metadata": {
    "id": "_BJzOAOM_QFW"
   },
   "source": [
    "## 3.2 Deploy the Application Package\n",
    "\n",
    "The app is now defined and ready to deploy to Vespa Cloud.\n",
    "\n",
    "Deploy `package` to Vespa Cloud, by creating an instance of\n",
    "[VespaCloud](https://vespa-engine.github.io/pyvespa/api/vespa/deployment#VespaCloud):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "or8HJb5Q26h5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "or8HJb5Q26h5",
    "outputId": "8c98f519-8185-4251-b93b-5814403b4143"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting application...\n",
      "Running: vespa config set application vespa-presales.videosearch.default\n",
      "Setting target cloud...\n",
      "Running: vespa config set target cloud\n",
      "\n",
      "No api-key found for control plane access. Using access token.\n",
      "Checking for access token in auth.json...\n",
      "Access token expired. Please re-authenticate.\n",
      "Your Device Confirmation code is: MJKL-VTBW\n",
      "Automatically open confirmation page in your default browser? [Y/n] \n",
      "Opened link in your browser: https://login.console.vespa-cloud.com/activate?user_code=MJKL-VTBW\n",
      "Waiting for login to complete in browser ... done;1m⣽\u001b[0;22m\n",
      "\u001b[32mSuccess:\u001b[0m Logged in\n",
      " auth.json created at /Users/zohar/.vespa/auth.json\n",
      "Successfully obtained access token for control plane access.\n"
     ]
    }
   ],
   "source": [
    "vespa_cloud = VespaCloud(\n",
    "    tenant=tenant_name,\n",
    "    application=application,\n",
    "    application_package=package,\n",
    "    key_content=os.getenv(\"VESPA_TEAM_API_KEY\", None),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "nLeaLna86ApZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nLeaLna86ApZ",
    "outputId": "9eb4c057-f13a-4164-f2ed-eecc968c6f96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment started in run 19 of dev-aws-us-east-1c for vespa-presales.videosearch. This may take a few minutes the first time.\n",
      "INFO    [16:48:18]  Deploying platform version 8.547.15 and application dev build 11 for dev-aws-us-east-1c of default ...\n",
      "INFO    [16:48:18]  Using CA signed certificate version 3\n",
      "INFO    [16:48:18]  Using 1 nodes in container cluster 'videosearch_container'\n",
      "INFO    [16:48:21]  Session 7523 for tenant 'vespa-presales' prepared and activated.\n",
      "INFO    [16:48:21]  ######## Details for all nodes ########\n",
      "INFO    [16:48:21]  h121570a.dev.us-east-1c.aws.vespa-cloud.net: expected to be UP\n",
      "INFO    [16:48:21]  --- platform vespa/cloud-tenant-rhel8:8.547.15\n",
      "INFO    [16:48:21]  --- container on port 4080 has config generation 7522, wanted is 7523\n",
      "INFO    [16:48:21]  --- metricsproxy-container on port 19092 has config generation 7522, wanted is 7523\n",
      "INFO    [16:48:21]  h119160h.dev.us-east-1c.aws.vespa-cloud.net: expected to be UP\n",
      "INFO    [16:48:21]  --- platform vespa/cloud-tenant-rhel8:8.547.15\n",
      "INFO    [16:48:21]  --- container-clustercontroller on port 19050 has config generation 7522, wanted is 7523\n",
      "INFO    [16:48:21]  --- metricsproxy-container on port 19092 has config generation 7523, wanted is 7523\n",
      "INFO    [16:48:21]  h117409h.dev.us-east-1c.aws.vespa-cloud.net: expected to be UP\n",
      "INFO    [16:48:21]  --- platform vespa/cloud-tenant-rhel8:8.547.15\n",
      "INFO    [16:48:21]  --- logserver-container on port 4080 has config generation 7523, wanted is 7523\n",
      "INFO    [16:48:21]  --- metricsproxy-container on port 19092 has config generation 7522, wanted is 7523\n",
      "INFO    [16:48:21]  h121486b.dev.us-east-1c.aws.vespa-cloud.net: expected to be UP\n",
      "INFO    [16:48:21]  --- platform vespa/cloud-tenant-rhel8:8.547.15\n",
      "INFO    [16:48:21]  --- storagenode on port 19102 has config generation 7522, wanted is 7523\n",
      "INFO    [16:48:21]  --- searchnode on port 19107 has config generation 7523, wanted is 7523\n",
      "INFO    [16:48:21]  --- distributor on port 19111 has config generation 7523, wanted is 7523\n",
      "INFO    [16:48:21]  --- metricsproxy-container on port 19092 has config generation 7523, wanted is 7523\n",
      "INFO    [16:48:29]  Found endpoints:\n",
      "INFO    [16:48:29]  - dev.aws-us-east-1c\n",
      "INFO    [16:48:29]   |-- https://d4ed0f5e.ee8b6819.z.vespa-app.cloud/ (cluster 'videosearch_container')\n",
      "INFO    [16:48:30]  Deployment of new application revision complete!\n",
      "Only region: aws-us-east-1c available in dev environment.\n",
      "Found mtls endpoint for videosearch_container\n",
      "URL: https://d4ed0f5e.ee8b6819.z.vespa-app.cloud/\n",
      "Application is up!\n"
     ]
    }
   ],
   "source": [
    "app = vespa_cloud.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v-58uKvQ_78K",
   "metadata": {
    "id": "v-58uKvQ_78K"
   },
   "source": [
    "## 3.3 Feed the Vespa Application\n",
    "\n",
    "The `vespa_feed` feed format for `pyvespa` expects a dict with the keys `id` and `fields`:\n",
    "\n",
    "`{ \"id\": \"vespa-document-id\", \"fields\": {\"vespa_field\": \"vespa-field-value\"}}`\n",
    "\n",
    "For the id, we will use a md5 hash of the video url.\n",
    "\n",
    "The video embedding output segments are added to the `fields` in `vespa_feed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfpazeii8Abp",
   "metadata": {
    "id": "dfpazeii8Abp"
   },
   "outputs": [],
   "source": [
    "# Initialize a list to store Vespa feed documents\n",
    "vespa_feed = []\n",
    "\n",
    "# Need to reverse VIDEO_URLS as keywords/summaries generated in reverse order\n",
    "VIDEO_URLs.reverse()\n",
    "\n",
    "# Iterate through each task and corresponding metadata\n",
    "for i, task in enumerate(tasks):\n",
    "    video_url = VIDEO_URLs[i]\n",
    "    title = titles[i]\n",
    "    keywords = keywords_array[i]\n",
    "    summary = summaries[i]\n",
    "\n",
    "    start_offsets = []  # Reset for each video\n",
    "    end_offsets = []  # Reset for each video\n",
    "    embeddings = {}  # Reset for each video\n",
    "\n",
    "    # Iterate through the video embedding segments\n",
    "    for index, segment in enumerate(task.video_embedding.segments):\n",
    "        # Append start and end offsets as floats\n",
    "        start_offsets.append(float(segment.start_offset_sec))\n",
    "        end_offsets.append(float(segment.end_offset_sec))\n",
    "\n",
    "        # Add embedding to a multi-dimensional dictionary with index as the key\n",
    "        embeddings[str(index)] = list(map(float, segment.embeddings_float))\n",
    "\n",
    "    # Create Vespa document for each task\n",
    "    for segment in task.video_embedding.segments:\n",
    "        start_offset_sec = segment.start_offset_sec\n",
    "        end_offset_sec = segment.end_offset_sec\n",
    "        embedding = list(map(float, segment.embeddings_float))\n",
    "\n",
    "        # Create a unique ID by hashing the URL and segment index\n",
    "        id_hash = hashlib.md5(f\"{video_url}_{index}\".encode()).hexdigest()\n",
    "\n",
    "        document = {\n",
    "            \"id\": id_hash,\n",
    "            \"fields\": {\n",
    "                \"video_url\": video_url,\n",
    "                \"title\": title,\n",
    "                \"keywords\": keywords,\n",
    "                \"video_summary\": summary,\n",
    "                \"embedding_scope\": segment.embedding_scope,\n",
    "                \"start_offset_sec\": start_offsets,\n",
    "                \"end_offset_sec\": end_offsets,\n",
    "                \"embeddings\": embeddings,\n",
    "            },\n",
    "        }\n",
    "    vespa_feed.append(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G7KUVns0BSzZ",
   "metadata": {
    "id": "G7KUVns0BSzZ"
   },
   "source": [
    "We can quickly validate the number of the number of documents created (one for each video), and visually check the first record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aZDNkQEXMU15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aZDNkQEXMU15",
    "outputId": "2e7c2fa2-ec78-48a2-eb2a-535d205d1b36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents created: 3\n"
     ]
    }
   ],
   "source": [
    "# Print Vespa feed size and an example\n",
    "print(f\"Total documents created: {len(vespa_feed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "TF2GsukrA9Xw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TF2GsukrA9Xw",
    "outputId": "4e2b3e49-f2fa-40c5-f2db-b013dd69cac5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"93d8476bee530eb39a2122f586d0d13a\",\n",
      "    \"fields\": {\n",
      "        \"video_url\": \"https://archive.org/download/the-end-blue-sky-studios/The%20End%281080P_60FPS%29.ia.mp4\",\n",
      "        \"title\": \"The END (Blue Sky Studios)\",\n",
      "        \"keywords\": \"squirrel, acorn, winter, snow, forest\",\n",
      "        \"video_summary\": \"The video captures a serene snowy landscape with pine trees under a cloudy sky, where a squirrel emerges from behind a rock formation carrying an acorn. Upon noticing another acorn in the foreground, the squirrel appears momentarily surprised, as indicated by its vocalization \\\"Oh...\\\". It then drops one acorn and begins to nibble on the other, eventually discarding fragments of it before leaping away. The scene concludes with the squirrel's departure, leaving behind the remnants of the acorn, as darkness gradually engulfs the snowy setting.\",\n",
      "        \"embedding_scope\": \"clip\",\n",
      "        \"start_offset_sec\": [\n",
      "            0.0,\n",
      "            6.0,\n",
      "            12.0\n",
      "        ],\n",
      "        \"end_offset_sec\": [\n",
      "            6.0,\n",
      "            12.0,\n",
      "            18.0\n",
      "        ],\n",
      "        \"embedding\": {\n",
      "            \"0\": [\n",
      "                0.05419811,\n",
      "                -0.0018933096,\n",
      "                0.008044507\n",
      "            ],\n",
      "            \"1\": [\n",
      "                0.016035125,\n",
      "                -0.015930071,\n",
      "                0.022429857\n",
      "            ],\n",
      "            \"2\": [\n",
      "                0.014023403,\n",
      "                -0.012773005,\n",
      "                0.019988379\n",
      "            ]\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# The positional index of the document\n",
    "i = 0\n",
    "\n",
    "# Iterate through the first 3 embeddings in vespa_feed\n",
    "for i in range(\n",
    "    min(3, len(vespa_feed))\n",
    "):  # Ensure we don't exceed the length of vespa_feed\n",
    "    # Limit the embedding to the first 3 keys and first 5 values for each key\n",
    "    embedding = vespa_feed[i][\"fields\"][\"embeddings\"]\n",
    "    embedding_sample = {key: values[:3] for key, values in list(embedding.items())[:3]}\n",
    "\n",
    "# Beautify and print the first document with only the first 5 embedding values\n",
    "pretty_json = json.dumps(\n",
    "    {\n",
    "        \"id\": vespa_feed[i][\"id\"],\n",
    "        \"fields\": {\n",
    "            \"video_url\": vespa_feed[i][\"fields\"][\"video_url\"],\n",
    "            \"title\": vespa_feed[i][\"fields\"][\"title\"],\n",
    "            \"keywords\": vespa_feed[i][\"fields\"][\"keywords\"],\n",
    "            \"video_summary\": vespa_feed[i][\"fields\"][\"video_summary\"],\n",
    "            \"embedding_scope\": vespa_feed[i][\"fields\"][\"embedding_scope\"],\n",
    "            \"start_offset_sec\": vespa_feed[i][\"fields\"][\"start_offset_sec\"][:3],\n",
    "            \"end_offset_sec\": vespa_feed[i][\"fields\"][\"end_offset_sec\"][:3],\n",
    "            \"embedding\": embedding_sample,\n",
    "        },\n",
    "    },\n",
    "    indent=4,\n",
    ")\n",
    "\n",
    "print(pretty_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JPgWYO_zDfBY",
   "metadata": {
    "id": "JPgWYO_zDfBY"
   },
   "source": [
    "Now we can feed to Vespa using `feed_iterable` which accepts any `Iterable` and an optional callback function where we can\n",
    "check the outcome of each operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3d650aa",
   "metadata": {
    "id": "d3d650aa"
   },
   "outputs": [],
   "source": [
    "def callback(response: VespaResponse, id: str):\n",
    "    if not response.is_successful():\n",
    "        print(\n",
    "            f\"Failed to feed document {id} with status code {response.status_code}: Reason {response.get_json()}\"\n",
    "        )\n",
    "\n",
    "\n",
    "# Feed data into Vespa synchronously\n",
    "app.feed_iterable(vespa_feed, schema=\"videos\", callback=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1TmrMnhEQx2",
   "metadata": {
    "id": "e1TmrMnhEQx2"
   },
   "source": [
    "# 4. Performing search on the videos\n",
    "\n",
    "\n",
    "## 4.1 Performing a hybrid search on the video\n",
    "\n",
    "As an example query, we will retrieve all the chunks which shows Santa Claus on his sleigh. The first step is to generate a text embedding for `Santa Claus on his sleigh` using the `Marengo-retrieval-2.7` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8wxSLkGkpL8w",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8wxSLkGkpL8w",
    "outputId": "0ebfcab2-9e6d-4193-efbc-e3c3994492c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a text embedding\n",
      " Model: Marengo-retrieval-2.7\n",
      " Embedding Dimension: 1024\n",
      " Sample 5 values from array: [-0.018066406, -0.0065307617, 0.05859375, -0.033447266, -0.02368164]\n"
     ]
    }
   ],
   "source": [
    "client = TwelveLabs(api_key=TL_API_KEY)\n",
    "user_query = \"Santa Claus on his sleigh\"\n",
    "\n",
    "res = client.embed.create(\n",
    "    model_name=\"Marengo-retrieval-2.7\",\n",
    "    text=user_query,\n",
    ")\n",
    "\n",
    "print(\"Created a text embedding\")\n",
    "print(f\" Model: {res.model_name}\")\n",
    "if res.text_embedding is not None and res.text_embedding.segments is not None:\n",
    "    q_embedding = res.text_embedding.segments[0].embeddings_float\n",
    "    print(f\" Embedding Dimension: {len(q_embedding)}\")\n",
    "    print(f\" Sample 5 values from array: {q_embedding[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oOR1PuSRSlh4",
   "metadata": {
    "id": "oOR1PuSRSlh4"
   },
   "source": [
    "The following uses dense vector representations of the query embedding obtained previously and document and matching is performed and accelerated by Vespa's support for\n",
    "[approximate nearest neighbor search](https://docs.vespa.ai/en/approximate-nn-hnsw.html).\n",
    "\n",
    "The output is limited to the top 1 hit, as we only have a sample of 3 videos. The top hit returned was based on a hybrid ranking based on a bm25 ranking based on a lexical search on the text, keywords and summary of the video, performed as a first phase, and similarity search on the embeddings.\n",
    "\n",
    "We can see as part of the `match-features`, the segment 212 in the video was the one providing the highest match.\n",
    "\n",
    "We also calculate the similarities as part of the `summary-features` for the rest of the segments so we can look for top N segments within a video, optionally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "N4XEyB4pYC7l",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N4XEyB4pYC7l",
    "outputId": "836526cc-80b3-4758-c96c-4d40bc859298"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Metadata:\n",
      "documentid: id:videos:videos::d4175516790d7e55a79eb7f190495a92\n",
      "Relevance: 0.47162757625475055\n",
      "Source: videosearch_content\n",
      "Match Features: {'closest(embeddings)': {'type': 'tensor<float>(p{})', 'cells': {'212': 1.0}}}\n",
      "\n",
      "Title: Twas the night before Christmas\n",
      "Keywords: snowy village, clock tower, Santa Claus, mechanical gears, Christmas chimes\n",
      "Video URL: https://ia601401.us.archive.org/1/items/twas-the-night-before-christmas-1974-full-movie-freedownloadvideo.net/twas-the-night-before-christmas-1974-full-movie-freedownloadvideo.net.mp4\n",
      "Video Summary: The video is an animated adaptation of \"Twas The Night Before Christmas,\" featuring a blend of human and mouse characters. It begins with a snowy night scene and transitions to a clockmaker's workshop, where the clockmaker, Joshua Trundle, and his family face challenges after a critical letter to Santa is written by Albert, Trundle's son. The story unfolds with the town's efforts to reconcile with Santa through a special clock designed to play a welcoming song on Christmas Eve, but complications arise when the clock malfunctions. Despite the setbacks, the family and community work together to fix the clock and restore belief in Santa, culminating in his magical arrival, bringing joy and gifts to all. The video concludes with a heartfelt message about the power of belief and the importance of making amends.\n",
      "Embedding Scope: clip\n",
      "\n",
      "Details for cell 212:\n",
      "Start offset: 1272.0 sec\n",
      "End offset: 1278.0 sec\n",
      "Similarity score: 0.43537065386772156\n",
      "Match feature score: 1.0\n"
     ]
    }
   ],
   "source": [
    "with app.syncio(connections=1) as session:\n",
    "    response: VespaQueryResponse = session.query(\n",
    "        yql=\"select * from videos where userQuery() OR ({targetHits:100}nearestNeighbor(embeddings,q))\",\n",
    "        query=user_query,\n",
    "        ranking=\"hybrid\",\n",
    "        hits=1,\n",
    "        body={\"input.query(q)\": q_embedding},\n",
    "    )\n",
    "    assert response.is_successful()\n",
    "\n",
    "hit = response.hits[0]\n",
    "\n",
    "# Extract metadata\n",
    "doc_id = hit.get(\"id\")\n",
    "relevance = hit.get(\"relevance\")\n",
    "source = hit.get(\"source\")\n",
    "fields = hit.get(\"fields\", {})\n",
    "\n",
    "# Extract the embedding match cell index (first key in matchfeatures)\n",
    "match_cells = fields.get(\"matchfeatures\", {}).get(\"closest(embeddings)\", {}).get(\"cells\", {})\n",
    "if not match_cells:\n",
    "    raise ValueError(\"No cells found in matchfeatures.closest(embeddings)\")\n",
    "\n",
    "# Get the first (and only) cell key and value\n",
    "cell_index, cell_value = next(iter(match_cells.items()))\n",
    "cell_index = int(cell_index)  # Convert key from string to int\n",
    "\n",
    "# Extract aligned fields using the index\n",
    "start_offset = fields.get(\"start_offset_sec\", [])[cell_index]\n",
    "end_offset = fields.get(\"end_offset_sec\", [])[cell_index]\n",
    "similarity = fields.get(\"summaryfeatures\", {}).get(\"similarities\", {}).get(\"cells\", {}).get(str(cell_index))\n",
    "\n",
    "# Print full info\n",
    "print(\"Document Metadata:\")\n",
    "print(f\"documentid: {doc_id}\")\n",
    "print(f\"Relevance: {relevance}\")\n",
    "print(f\"Source: {source}\")\n",
    "print(f\"Match Features: {fields.get('matchfeatures', 'N/A')}\")\n",
    "print()\n",
    "\n",
    "print(f\"Title: {fields.get('title', 'N/A')}\")\n",
    "print(f\"Keywords: {fields.get('keywords', 'N/A')}\")\n",
    "print(f\"Video URL: {fields.get('video_url', 'N/A')}\")\n",
    "print(f\"Video Summary: {fields.get('video_summary', 'N/A')}\")\n",
    "print(f\"Embedding Scope: {fields.get('embedding_scope', 'N/A')}\")\n",
    "print()\n",
    "\n",
    "# Print details for the matched cell\n",
    "print(f\"Details for cell {cell_index}:\")\n",
    "print(f\"Start offset: {start_offset} sec\")\n",
    "print(f\"End offset: {end_offset} sec\")\n",
    "print(f\"Similarity score: {similarity}\")\n",
    "print(f\"Match feature score: {cell_value}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f09ea78",
   "metadata": {},
   "source": [
    "You should see output similar to this:\n",
    "\n",
    "```Document Metadata:\n",
    "documentid: id:videos:videos::d4175516790d7e55a79eb7f190495a92\n",
    "Relevance: 0.47162757625475055\n",
    "Source: videosearch_content\n",
    "Match Features: {'closest(embeddings)': {'type': 'tensor<float>(p{})', 'cells': {'212': 1.0}}}\n",
    "\n",
    "Title: Twas the night before Christmas\n",
    "Keywords: snowy village, clock tower, Santa Claus, mechanical gears, Christmas chimes\n",
    "Video URL: https://ia601401.us.archive.org/1/items/twas-the-night-before-christmas-1974-full-movie-freedownloadvideo.net/twas-the-night-before-christmas-1974-full-movie-freedownloadvideo.net.mp4\n",
    "Video Summary: The video is an animated adaptation of \"Twas The Night Before Christmas,\" featuring a blend of human and mouse characters. It begins with a snowy night scene and transitions to a clockmaker's workshop, where the clockmaker, Joshua Trundle, and his family face challenges after a critical letter to Santa is written by Albert, Trundle's son. The story unfolds with the town's efforts to reconcile with Santa through a special clock designed to play a welcoming song on Christmas Eve, but complications arise when the clock malfunctions. Despite the setbacks, the family and community work together to fix the clock and restore belief in Santa, culminating in his magical arrival, bringing joy and gifts to all. The video concludes with a heartfelt message about the power of belief and the importance of making amends.\n",
    "Embedding Scope: clip\n",
    "\n",
    "Details for cell 212:\n",
    "Start offset: 1272.0 sec\n",
    "End offset: 1278.0 sec\n",
    "Similarity score: 0.43537065386772156\n",
    "Match feature score: 1.0```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bnbWlc62nhyb",
   "metadata": {
    "id": "bnbWlc62nhyb"
   },
   "source": [
    "In order to process the results above in a more consumable format and sort out the top N segments based on similarities, we can do this more conveniently in a pandas dataframe below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "vGDIF53MvkdR",
   "metadata": {
    "id": "vGDIF53MvkdR"
   },
   "outputs": [],
   "source": [
    "def get_top_n_similarity_matches(data, N=5):\n",
    "    \"\"\"\n",
    "    Function to extract the top N similarity scores and their corresponding start and end offsets.\n",
    "\n",
    "    Args:\n",
    "    - data (dict): Input JSON-like structure containing similarities and offsets.\n",
    "    - N (int): The number of top similarity scores to return.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A DataFrame with the top N similarity scores and their corresponding offsets.\n",
    "    \"\"\"\n",
    "    # Extract relevant fields\n",
    "    similarities = data[\"fields\"][\"summaryfeatures\"][\"similarities\"][\"cells\"]\n",
    "    start_offset_sec = data[\"fields\"][\"start_offset_sec\"]\n",
    "    end_offset_sec = data[\"fields\"][\"end_offset_sec\"]\n",
    "\n",
    "    # Convert similarity scores to a list of tuples (index, similarity_score) and sort by similarity score\n",
    "    sorted_similarities = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Extract top N similarity scores\n",
    "    top_n_similarities = sorted_similarities[:N]\n",
    "\n",
    "    # Prepare results\n",
    "    results = []\n",
    "    for index_str, score in top_n_similarities:\n",
    "        index = int(index_str)\n",
    "        if index < len(start_offset_sec):\n",
    "            result = {\n",
    "                \"index\": index,\n",
    "                \"similarity_score\": score,\n",
    "                \"start_offset_sec\": start_offset_sec[index],\n",
    "                \"end_offset_sec\": end_offset_sec[index],\n",
    "            }\n",
    "        else:\n",
    "            result = {\n",
    "                \"index\": index,\n",
    "                \"similarity_score\": score,\n",
    "                \"start_offset_sec\": None,\n",
    "                \"end_offset_sec\": None,\n",
    "            }\n",
    "        results.append(result)\n",
    "\n",
    "    # Convert results to a DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ySanRKGLpAjB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "ySanRKGLpAjB",
    "outputId": "ae8f0c5c-fd03-41a5-fc6e-880685c13818"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>start_offset_sec</th>\n",
       "      <th>end_offset_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>212</td>\n",
       "      <td>0.435371</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>1278.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230</td>\n",
       "      <td>0.418007</td>\n",
       "      <td>1380.0</td>\n",
       "      <td>1386.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210</td>\n",
       "      <td>0.411242</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>1266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "      <td>0.409344</td>\n",
       "      <td>1266.0</td>\n",
       "      <td>1272.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>208</td>\n",
       "      <td>0.408644</td>\n",
       "      <td>1248.0</td>\n",
       "      <td>1254.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>231</td>\n",
       "      <td>0.406000</td>\n",
       "      <td>1386.0</td>\n",
       "      <td>1392.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>209</td>\n",
       "      <td>0.404767</td>\n",
       "      <td>1254.0</td>\n",
       "      <td>1260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>229</td>\n",
       "      <td>0.403729</td>\n",
       "      <td>1374.0</td>\n",
       "      <td>1380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>203</td>\n",
       "      <td>0.403292</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>1224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>207</td>\n",
       "      <td>0.391671</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>1248.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  similarity_score  start_offset_sec  end_offset_sec\n",
       "0    212          0.435371            1272.0          1278.0\n",
       "1    230          0.418007            1380.0          1386.0\n",
       "2    210          0.411242            1260.0          1266.0\n",
       "3    211          0.409344            1266.0          1272.0\n",
       "4    208          0.408644            1248.0          1254.0\n",
       "5    231          0.406000            1386.0          1392.0\n",
       "6    209          0.404767            1254.0          1260.0\n",
       "7    229          0.403729            1374.0          1380.0\n",
       "8    203          0.403292            1218.0          1224.0\n",
       "9    207          0.391671            1242.0          1248.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = get_top_n_similarity_matches(response.hits[0], N=10)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sYoc3zy3pNqV",
   "metadata": {
    "id": "sYoc3zy3pNqV"
   },
   "source": [
    "## 5. Review results (Optional)\n",
    "\n",
    "We can review the results by spinning up a video player in the notebook and check the segments identified and judge by ourselves.\n",
    "\n",
    "But, first we need to obtain the contiguous segments, add 3 seconds overlap in the consolidated segments and convert to MM:SS so we can quickly find the segments to watch in the player. Let's write a function that takes the response as an input and provides the consolidated segments to view in the player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "244lqkpvymGH",
   "metadata": {
    "id": "244lqkpvymGH"
   },
   "outputs": [],
   "source": [
    "def concatenate_contiguous_segments(df):\n",
    "    \"\"\"\n",
    "    Function to concatenate contiguous segments based on their start and end offsets.\n",
    "    Converts the concatenated segments to MM:SS format.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame with columns 'start_offset_sec' and 'end_offset_sec'.\n",
    "\n",
    "    Returns:\n",
    "    - List of tuples with concatenated segments in MM:SS format as (start_time, end_time).\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return []\n",
    "\n",
    "    # Sort by start_offset_sec for ordered processing\n",
    "    df = df.sort_values(by=\"start_offset_sec\").reset_index(drop=True)\n",
    "\n",
    "    # Initialize the list to hold concatenated segments\n",
    "    concatenated_segments = []\n",
    "\n",
    "    # Initialize the first segment\n",
    "    start = df.iloc[0][\"start_offset_sec\"]\n",
    "    end = df.iloc[0][\"end_offset_sec\"]\n",
    "\n",
    "    for i in range(1, len(df)):\n",
    "        current_start = df.iloc[i][\"start_offset_sec\"]\n",
    "        current_end = df.iloc[i][\"end_offset_sec\"]\n",
    "\n",
    "        # Check if the current segment is contiguous with the previous one\n",
    "        if current_start <= end:\n",
    "            # Extend the segment if it is contiguous\n",
    "            end = max(end, current_end)\n",
    "        else:\n",
    "            # Add the previous segment to the result list in MM:SS format\n",
    "            concatenated_segments.append(\n",
    "                (convert_seconds_to_mmss(start - 3), convert_seconds_to_mmss(end + 3))\n",
    "            )\n",
    "            # Start a new segment\n",
    "            start = current_start\n",
    "            end = current_end\n",
    "\n",
    "    # Add the final segment\n",
    "    concatenated_segments.append(\n",
    "        (convert_seconds_to_mmss(start - 3), convert_seconds_to_mmss(end + 3))\n",
    "    )\n",
    "\n",
    "    return concatenated_segments\n",
    "\n",
    "\n",
    "def convert_seconds_to_mmss(seconds):\n",
    "    \"\"\"\n",
    "    Converts seconds to MM:SS format.\n",
    "\n",
    "    Args:\n",
    "    - seconds (float): Time in seconds.\n",
    "\n",
    "    Returns:\n",
    "    - str: Time in MM:SS format.\n",
    "    \"\"\"\n",
    "    minutes = int(seconds // 60)\n",
    "    seconds = int(seconds % 60)\n",
    "    return f\"{minutes:02}:{seconds:02}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "azg1FfNCzEpV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "azg1FfNCzEpV",
    "outputId": "610f5977-9a9c-4cca-bb12-eb639acea71e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('20:15', '20:27'), ('20:39', '21:21'), ('22:51', '23:15')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments = concatenate_contiguous_segments(df_result)\n",
    "segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XKK-tQMGp57L",
   "metadata": {
    "id": "XKK-tQMGp57L"
   },
   "source": [
    "We can now spin-up the player and review the segments of interest.\n",
    "Video player is set to start in the middle of the first segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "brwDc367FHzX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "brwDc367FHzX",
    "outputId": "a6b5a8d5-c696-4a38-f09c-9bcd31eb22a6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video id=\"myVideo\" width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"https://ia601401.us.archive.org/1/items/twas-the-night-before-christmas-1974-full-movie-freedownloadvideo.net/twas-the-night-before-christmas-1974-full-movie-freedownloadvideo.net.mp4\" type=\"video/mp4\">\n",
       "  Your browser does not support the video tag.\n",
       "</video>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "video_url = \"https://ia601401.us.archive.org/1/items/twas-the-night-before-christmas-1974-full-movie-freedownloadvideo.net/twas-the-night-before-christmas-1974-full-movie-freedownloadvideo.net.mp4\"\n",
    "\n",
    "video_player = f\"\"\"\n",
    "<video id=\"myVideo\" width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{video_url}\" type=\"video/mp4\">\n",
    "  Your browser does not support the video tag.\n",
    "</video>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "HTML(video_player)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf10c4db",
   "metadata": {
    "id": "cf10c4db"
   },
   "source": [
    "## 6. Clean-up\n",
    "\n",
    "The following will delete the application and data from the dev environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a9d44767",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9d44767",
    "outputId": "866323ba-9e02-43f4-98b2-29feeefea21f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deactivated vespa-presales.videosearch in dev.aws-us-east-1c\n",
      "Deleted instance vespa-presales.videosearch.default\n"
     ]
    }
   ],
   "source": [
    "vespa_cloud.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "B4zTc3eApSFy",
   "metadata": {
    "id": "B4zTc3eApSFy"
   },
   "source": [
    "The following will delete the index created earlier where videos where uploaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7BAlC6R8pZD1",
   "metadata": {
    "id": "7BAlC6R8pZD1"
   },
   "outputs": [],
   "source": [
    "# Creating a client\n",
    "client = TwelveLabs(api_key=TL_API_KEY)\n",
    "\n",
    "client.index.delete(index_id)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "vespa-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
