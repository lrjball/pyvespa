{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "d551cc4e",
            "metadata": {
                "id": "b3ae8a2b"
            },
            "source": []
        },
        {
            "cell_type": "markdown",
            "id": "0dd50339",
            "metadata": {},
            "source": [
                "<picture>\n",
                "  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://assets.vespa.ai/logos/Vespa-logo-green-RGB.svg\">\n",
                "  <source media=\"(prefers-color-scheme: light)\" srcset=\"https://assets.vespa.ai/logos/Vespa-logo-dark-RGB.svg\">\n",
                "  <img alt=\"#Vespa\" width=\"200\" src=\"https://assets.vespa.ai/logos/Vespa-logo-dark-RGB.svg\" style=\"margin-bottom: 25px;\">\n",
                "</picture>\n",
                "\n",
                "# Multilingual Hybrid Search with Cohere binary embeddings and Vespa\n",
                "\n",
                "Cohere just released a new embedding API supporting binary vectors. Read the announcement\n",
                "in the blog post: [Cohere int8 & binary Embeddings - Scale Your Vector Database to Large Datasets](https://cohere.com/blog/int8-binary-embeddings).\n",
                "\n",
                "> We are excited to announce that Cohere Embed is the first embedding model that natively supports int8 and binary embeddings.\n",
                "\n",
                "This notebook demonstrates:\n",
                "\n",
                "- Building a multilingual search application over a sample of the German split of Wikipedia using [binarized cohere embeddings](https://huggingface.co/datasets/Cohere/wikipedia-2023-11-embed-multilingual-v3-int8-binary)\n",
                "- Indexing multiple binary embeddings per document; without having to split the chunks across multiple retrievable units\n",
                "- Hybrid search, combining the lexical matching capabilities of Vespa with Cohere binary embeddings\n",
                "- Re-scoring the binarized vectors for improved accuracy\n",
                "\n",
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vespa-engine/pyvespa/blob/master/docs/sphinx/source/examples/multilingual-multi-vector-reps-with-cohere-cloud.ipynb)\n",
                "\n",
                "Install the dependencies:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "daf34cf5",
            "metadata": {
                "id": "4ffa3cbe"
            },
            "outputs": [],
            "source": [
                "!pip3 install -U pyvespa cohere==4.57 datasets vespacli"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2ba2d86e",
            "metadata": {},
            "source": [
                "## Dataset exploration\n",
                "\n",
                "Cohere has released a large [Wikipedia dataset](https://huggingface.co/datasets/Cohere/wikipedia-2023-11-embed-multilingual-v3-int8-binary)\n",
                "\n",
                "> This dataset contains the wikimedia/wikipedia dataset dump from 2023-11-01 from Wikipedia in all 300+ languages. The embeddings are provided as int8 and ubinary that allow quick search and reduction of your vector index size up to 32.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9a378b88",
            "metadata": {},
            "outputs": [],
            "source": [
                "from datasets import load_dataset\n",
                "\n",
                "lang = \"de\"  # Use the first 10K chunks from the German Wikipedia subset\n",
                "docs = load_dataset(\n",
                "    \"Cohere/wikipedia-2023-11-embed-multilingual-v3-int8-binary\",\n",
                "    lang,\n",
                "    split=\"train\",\n",
                "    streaming=True,\n",
                ").take(10000)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b3f11700",
            "metadata": {},
            "source": [
                "## Aggregate from chunks to pages\n",
                "\n",
                "We want to aggregate the chunk <> vector representations into their natural retrievable unit - a Wikipedia page. We can still search\n",
                "the chunks and the chunk vector representation but retrieve pages instead of chunks. This avoids duplicating page-level metadata like url and title, while\n",
                "still being able to have meaningful semantic search representations. For RAG applications, this also means that we have the full page level context available\n",
                "when we retrieve information for the generative phase.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 160,
            "id": "1e3bf915",
            "metadata": {},
            "outputs": [],
            "source": [
                "pages = dict()\n",
                "for d in docs:\n",
                "    url = d[\"url\"]\n",
                "    if url not in pages:\n",
                "        pages[url] = [d]\n",
                "    else:\n",
                "        pages[url].append(d)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 173,
            "id": "e7d99904",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1866\n"
                    ]
                }
            ],
            "source": [
                "print(len(list(pages.keys())))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "74ec69ca",
            "metadata": {
                "id": "da356d25"
            },
            "source": [
                "## Defining the Vespa application\n",
                "\n",
                "First, we define a [Vespa schema](https://docs.vespa.ai/en/schemas.html) with the fields we want to store and their type.\n",
                "\n",
                "We use Vespa's multi-vector indexing support - See [Revolutionizing Semantic Search with Multi-Vector HNSW Indexing in Vespa](https://blog.vespa.ai/semantic-search-with-multi-vector-indexing/)\n",
                "for details. Highlights\n",
                "\n",
                "- language for language-specific [linguistic](https://docs.vespa.ai/en/linguistics.html) processing for keyword search\n",
                "- Two named multi-vector representations with different precision and in-memory versus off-memory\n",
                "- The named multi-vector representations holds the chunk-level embeddings\n",
                "- Chunks is an array of string where we enable BM25\n",
                "- Metadata for the page (url, title)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 174,
            "id": "29105961",
            "metadata": {
                "executionInfo": {
                    "elapsed": 224,
                    "status": "ok",
                    "timestamp": 1706652002196,
                    "user": {
                        "displayName": "Andreas Eriksen",
                        "userId": "00161553861396505040"
                    },
                    "user_tz": -60
                },
                "id": "0dca2378"
            },
            "outputs": [],
            "source": [
                "from vespa.package import Schema, Document, Field, FieldSet\n",
                "\n",
                "my_schema = Schema(\n",
                "    name=\"page\",\n",
                "    mode=\"index\",\n",
                "    document=Document(\n",
                "        fields=[\n",
                "            Field(name=\"doc_id\", type=\"string\", indexing=[\"summary\"]),\n",
                "            Field(\n",
                "                name=\"language\",\n",
                "                type=\"string\",\n",
                "                indexing=[\"summary\", \"index\", \"set_language\"],\n",
                "                match=[\"word\"],\n",
                "                rank=\"filter\",\n",
                "            ),\n",
                "            Field(\n",
                "                name=\"title\",\n",
                "                type=\"string\",\n",
                "                indexing=[\"summary\", \"index\"],\n",
                "                index=\"enable-bm25\",\n",
                "            ),\n",
                "            Field(\n",
                "                name=\"chunks\",\n",
                "                type=\"array<string>\",\n",
                "                indexing=[\"summary\", \"index\"],\n",
                "                index=\"enable-bm25\",\n",
                "            ),\n",
                "            Field(\n",
                "                name=\"url\",\n",
                "                type=\"string\",\n",
                "                indexing=[\"summary\", \"index\"],\n",
                "                index=\"enable-bm25\",\n",
                "            ),\n",
                "            Field(\n",
                "                name=\"binary_vectors\",\n",
                "                type=\"tensor<int8>(chunk{}, x[128])\",\n",
                "                indexing=[\"attribute\", \"index\"],\n",
                "                attribute=[\"distance-metric: hamming\"],\n",
                "            ),\n",
                "            Field(\n",
                "                name=\"int8_vectors\",\n",
                "                type=\"tensor<int8>(chunk{}, x[1024])\",\n",
                "                indexing=[\"attribute\"],\n",
                "                attribute=[\"paged\"],\n",
                "            ),\n",
                "        ]\n",
                "    ),\n",
                "    fieldsets=[FieldSet(name=\"default\", fields=[\"chunks\", \"title\"])],\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bed768cb",
            "metadata": {},
            "source": [
                "We must add the schema to a Vespa [application package](https://docs.vespa.ai/en/application-packages.html).\n",
                "This consists of configuration files, schemas, models, and possibly even custom code (plugins).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "c371b01f",
            "metadata": {
                "executionInfo": {
                    "elapsed": 239,
                    "status": "ok",
                    "timestamp": 1706652007584,
                    "user": {
                        "displayName": "Andreas Eriksen",
                        "userId": "00161553861396505040"
                    },
                    "user_tz": -60
                },
                "id": "66c5da1d"
            },
            "outputs": [],
            "source": [
                "from vespa.package import ApplicationPackage\n",
                "\n",
                "vespa_app_name = \"wikipedia\"\n",
                "vespa_application_package = ApplicationPackage(name=vespa_app_name, schema=[my_schema])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9a3fe087",
            "metadata": {
                "id": "7fe3d7bd"
            },
            "source": [
                "In the last step, we configure [ranking](https://docs.vespa.ai/en/ranking.html) by adding `rank-profile`'s to the schema.\n",
                "\n",
                "`unpack_bits` unpacks the binary representation into a 1024-dimensional float vector [doc](https://docs.vespa.ai/en/reference/ranking-expressions.html#unpack-bits).\n",
                "\n",
                "We define two tensor inputs, one compact binary representation that is used for the nearestNeighbor search and one\n",
                "full version that is used in ranking.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 138,
            "id": "a5d13c7f",
            "metadata": {
                "executionInfo": {
                    "elapsed": 407,
                    "status": "ok",
                    "timestamp": 1706652010412,
                    "user": {
                        "displayName": "Andreas Eriksen",
                        "userId": "00161553861396505040"
                    },
                    "user_tz": -60
                },
                "id": "a8ce5624"
            },
            "outputs": [],
            "source": [
                "from vespa.package import RankProfile, FirstPhaseRanking, SecondPhaseRanking, Function\n",
                "\n",
                "\n",
                "rerank = RankProfile(\n",
                "    name=\"rerank\",\n",
                "    inputs=[\n",
                "        (\"query(q_binary)\", \"tensor<int8>(x[128])\"),\n",
                "        (\"query(q_int8)\", \"tensor<int8>(x[1024])\"),\n",
                "        (\"query(q_full)\", \"tensor<float>(x[1024])\"),\n",
                "    ],\n",
                "    functions=[\n",
                "        Function(  # this returns a tensor<float>(chunk{}, x[1024]) with values -1 or 1\n",
                "            name=\"unpack_binary_representation\",\n",
                "            expression=\"2*unpack_bits(attribute(binary_vectors)) -1\",\n",
                "        ),\n",
                "        Function(\n",
                "            name=\"all_chunks_cosine\",\n",
                "            expression=\"cosine_similarity(query(q_int8), attribute(int8_vectors),x)\",\n",
                "        ),\n",
                "        Function(\n",
                "            name=\"int8_float_dot_products\",\n",
                "            expression=\"sum(query(q_full)*unpack_binary_representation,x)\",\n",
                "        ),\n",
                "    ],\n",
                "    first_phase=FirstPhaseRanking(\n",
                "        expression=\"reduce(int8_float_dot_products, max, chunk)\"\n",
                "    ),\n",
                "    second_phase=SecondPhaseRanking(\n",
                "        expression=\"reduce(all_chunks_cosine, max, chunk)\"  # rescoring using the full query and a unpacked binary_vector\n",
                "    ),\n",
                "    match_features=[\n",
                "        \"distance(field, binary_vectors)\",\n",
                "        \"all_chunks_cosine\",\n",
                "        \"firstPhase\",\n",
                "        \"bm25(title)\",\n",
                "        \"bm25(chunks)\",\n",
                "    ],\n",
                ")\n",
                "my_schema.add_rank_profile(rerank)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c46c95aa",
            "metadata": {
                "id": "846545f9"
            },
            "source": [
                "## Deploy the application to Vespa Cloud\n",
                "\n",
                "With the configured application, we can deploy it to [Vespa Cloud](https://cloud.vespa.ai/en/).\n",
                "\n",
                "To deploy the application to Vespa Cloud we need to create a tenant in the Vespa Cloud:\n",
                "\n",
                "Create a tenant at [console.vespa-cloud.com](https://console.vespa-cloud.com/) (unless you already have one).\n",
                "This step requires a Google or GitHub account, and will start your [free trial](https://cloud.vespa.ai/en/free-trial).\n",
                "\n",
                "Make note of the tenant name, it is used in the next steps.\n",
                "\n",
                "> Note: Deployments to dev and perf expire after 7 days of inactivity, i.e., 7 days after running deploy. This applies to all plans, not only the Free Trial. Use the Vespa Console to extend the expiry period, or redeploy the application to add 7 more days.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "id": "3a11f211",
            "metadata": {
                "executionInfo": {
                    "elapsed": 339,
                    "status": "ok",
                    "timestamp": 1706652019048,
                    "user": {
                        "displayName": "Andreas Eriksen",
                        "userId": "00161553861396505040"
                    },
                    "user_tz": -60
                },
                "id": "b5fddf9f"
            },
            "outputs": [],
            "source": [
                "from vespa.deployment import VespaCloud\n",
                "import os\n",
                "\n",
                "# Replace with your tenant name from the Vespa Cloud Console\n",
                "tenant_name = \"vespa-team\"\n",
                "\n",
                "# Key is only used for CI/CD. Can be removed if logging in interactively\n",
                "key = os.getenv(\"VESPA_TEAM_API_KEY\", None)\n",
                "if key is not None:\n",
                "    key = key.replace(r\"\\n\", \"\\n\")  # To parse key correctly\n",
                "\n",
                "vespa_cloud = VespaCloud(\n",
                "    tenant=tenant_name,\n",
                "    application=vespa_app_name,\n",
                "    key_content=key,  # Key is only used for CI/CD. Can be removed if logging in interactively\n",
                "    application_package=vespa_application_package,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cc1c140a",
            "metadata": {
                "id": "fa9baa5a"
            },
            "source": [
                "Now deploy the app to Vespa Cloud dev zone.\n",
                "\n",
                "The first deployment typically takes 2 minutes until the endpoint is up.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "494f5144",
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 12057,
                    "status": "ok",
                    "timestamp": 1706652033883,
                    "user": {
                        "displayName": "Andreas Eriksen",
                        "userId": "00161553861396505040"
                    },
                    "user_tz": -60
                },
                "id": "fe954dc4",
                "outputId": "6150363c-cfac-4240-e790-f84f98c481b0"
            },
            "outputs": [],
            "source": [
                "from vespa.application import Vespa\n",
                "\n",
                "app: Vespa = vespa_cloud.deploy()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "abc3be8f",
            "metadata": {
                "id": "54db44b1"
            },
            "source": [
                "## Feed the Wikipedia pages and the embedding representations\n",
                "\n",
                "Read more about feeding with pyvespa in [PyVespa:reads and writes](https://pyvespa.readthedocs.io/en/latest/reads-writes.html).\n",
                "\n",
                "In this case, we use a generator to yield document operations\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 153,
            "id": "00815efd",
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_vespa_feed_documents(pages):\n",
                "    for url, chunks in pages.items():\n",
                "        title = None\n",
                "        text_chunks = []\n",
                "        binary_vectors = {}\n",
                "        int8_vectors = {}\n",
                "        for chunk_id, chunk in enumerate(chunks):\n",
                "            title = chunk[\"title\"]\n",
                "            text = chunk[\"text\"]\n",
                "            text_chunks.append(text)\n",
                "            emb_ubinary = chunk[\"emb_ubinary\"]\n",
                "            emb_ubinary = [x - 128 for x in emb_ubinary]\n",
                "            emb_int8 = chunk[\"emb_int8\"]\n",
                "\n",
                "            binary_vectors[chunk_id] = emb_ubinary\n",
                "            int8_vectors[chunk_id] = emb_int8\n",
                "\n",
                "        vespa_json = {\n",
                "            \"id\": url,\n",
                "            \"fields\": {\n",
                "                \"doc_id\": url,\n",
                "                \"url\": url,\n",
                "                \"language\": lang,  # Assuming `lang` is defined somewhere\n",
                "                \"title\": title,\n",
                "                \"chunks\": text_chunks,\n",
                "                \"binary_vectors\": binary_vectors,\n",
                "                \"int8_vectors\": int8_vectors,\n",
                "            },\n",
                "        }\n",
                "        yield vespa_json"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 154,
            "id": "62f09b59",
            "metadata": {},
            "outputs": [],
            "source": [
                "from vespa.io import VespaResponse\n",
                "\n",
                "\n",
                "def callback(response: VespaResponse, id: str):\n",
                "    if not response.is_successful():\n",
                "        print(\n",
                "            f\"Failed to feed document {id} with status code {response.status_code}: Reason {response.get_json()}\"\n",
                "        )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 156,
            "id": "04c19b65",
            "metadata": {},
            "outputs": [],
            "source": [
                "app.feed_iterable(\n",
                "    iter=generate_vespa_feed_documents(pages),\n",
                "    schema=\"page\",\n",
                "    callback=callback,\n",
                "    max_queue_size=4000,\n",
                "    max_workers=16,\n",
                "    max_connections=16,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c39b1f1a",
            "metadata": {
                "id": "20b007ec"
            },
            "source": [
                "### Querying data\n",
                "\n",
                "Read more about querying Vespa in:\n",
                "\n",
                "- [Vespa Query API](https://docs.vespa.ai/en/query-api.html)\n",
                "- [Vespa Query API reference](https://docs.vespa.ai/en/reference/query-api-reference.html)\n",
                "- [Vespa Query Language API (YQL)](https://docs.vespa.ai/en/query-language.html)\n",
                "- [Practical Nearest Neighbor Search Guide](https://docs.vespa.ai/en/nearest-neighbor-search-guide.html)\n",
                "\n",
                "To obtain the query embedding we use the [Cohere embed API](https://docs.cohere.com/docs/embed-api).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "id": "89262f0b",
            "metadata": {},
            "outputs": [],
            "source": [
                "import cohere\n",
                "\n",
                "# Make sure that the environment variable CO_API_KEY is set to your API key\n",
                "co = cohere.Client()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 175,
            "id": "377da3d7",
            "metadata": {},
            "outputs": [],
            "source": [
                "query = 'Welche britische Rockband hat das Lied \"Spread Your Wings\"?'\n",
                "# Make sure to set input_type=\"search_query\" when getting the embeddings for the query.\n",
                "# We ask for 3 types of embeddings: float, binary, and int8\n",
                "query_emb = co.embed(\n",
                "    [query],\n",
                "    model=\"embed-multilingual-v3.0\",\n",
                "    input_type=\"search_query\",\n",
                "    embedding_types=[\"float\", \"binary\", \"int8\"],\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2d086ade",
            "metadata": {},
            "source": [
                "Now, we use the [nearestNeighbor](https://docs.vespa.ai/en/reference/query-language-reference.html#nearestneighbor) query operator to\n",
                "to retrieve 1000 pages using hamming distance. This phase uses the minimum chunk-level distance for selecting pages. Essentially finding\n",
                "the best chunk in the page. This ensures diversity as we retrieve pages, not chunks.\n",
                "\n",
                "These hits are exposed to the configured\n",
                "ranking phases that perform the re-ranking.\n",
                "\n",
                "Notice the language parameter, for language-specific processing of the query.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 158,
            "id": "686f1cf0",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'id': 'id:page:page::https:/de.wikipedia.org/wiki/Spread Your Wings',\n",
                            " 'relevance': 0.8184863924980164,\n",
                            " 'source': 'wikipedia_content',\n",
                            " 'fields': {'matchfeatures': {'bm25(chunks)': 28.125529605038967,\n",
                            "   'bm25(title)': 7.345395294159827,\n",
                            "   'distance(field,binary_vectors)': 170.0,\n",
                            "   'firstPhase': 8.274434089660645,\n",
                            "   'all_chunks_cosine': {'0': 0.8184863924980164,\n",
                            "    '1': 0.6203299760818481,\n",
                            "    '2': 0.643619954586029,\n",
                            "    '3': 0.6706648468971252,\n",
                            "    '4': 0.524447500705719,\n",
                            "    '5': 0.6730406880378723}},\n",
                            "  'sddocname': 'page',\n",
                            "  'documentid': 'id:page:page::https:/de.wikipedia.org/wiki/Spread Your Wings',\n",
                            "  'doc_id': 'https://de.wikipedia.org/wiki/Spread%20Your%20Wings',\n",
                            "  'language': 'de',\n",
                            "  'title': 'Spread Your Wings',\n",
                            "  'chunks': ['Spread Your Wings ist ein Lied der britischen Rockband Queen, das von deren Bassisten John Deacon geschrieben wurde. Es ist auf dem im Oktober 1977 erschienenen Album News of the World enthalten und wurde am 10. Februar 1978 in Europa als Single mit Sheer Heart Attack als B-Seite veröffentlicht. In Nordamerika wurde es nicht als Single veröffentlicht, sondern erschien stattdessen 1980 als B-Seite des Billboard Nummer-1-Hits Crazy Little Thing Called Love. Das Lied wurde zwar kein großer Hit in den Charts, ist aber unter Queen-Fans sehr beliebt.',\n",
                            "   'Der Text beschreibt einen jungen Mann namens Sammy, der in einer Bar zum Putzen arbeitet (“You should’ve been sweeping/up the Emerald bar”). Während sein Chef ihn in den Strophen beschimpft und sagt, er habe keinerlei Ambitionen und solle sich mit dem zufriedengeben, was er hat (“You’ve got no real ambition,/you won’t get very far/Sammy boy don’t you know who you are/Why can’t you be happy/at the Emerald bar”), ermuntert ihn der Erzähler im Refrain, seinen Träumen nachzugehen (“spread your wings and fly away/Fly away, far away/Pull yourself together ‘cause you know you should do better/That’s because you’re a free man.”).',\n",
                            "   'Das Lied ist im 4/4-Takt geschrieben, beginnt in der Tonart D-Dur, wechselt in der Bridge zu deren Paralleltonart h-Moll und endet wieder mit D-Dur. Es beginnt mit einem kurzen Piano-Intro, gefolgt von der ersten Strophe, die nur mit einer akustischen Gitarre, Piano und Hi-Hats begleitet wird, und dem Refrain, in dem die E-Gitarre und das Schlagzeug hinzukommen. Die Bridge besteht aus kurzen, langsamen Gitarrentönen. Die zweite Strophe enthält im Gegensatz zur ersten beinahe von Anfang an E-Gitarren-Klänge und Schlagzeugtöne. Darauf folgt nochmals der Refrain. Das Outro ist – abgesehen von zwei kurzen Rufen – instrumental. Es besteht aus einem längeren Gitarrensolo, in dem – was für Queen äußerst ungewöhnlich ist – dieselbe Akkordfolge mehrere Male wiederholt wird und ab dem vierten Mal langsam ausblendet. Das ganze Lied enthält keinerlei Hintergrundgesang, sondern nur den Leadgesang von Freddie Mercury.',\n",
                            "   'Das Musikvideo wurde ebenso wie das zu We Will Rock You im Januar 1978 im Garten von Roger Taylors damaligen Anwesen Millhanger House gedreht, welches sich im Dorf Thursley im Südwesten der englischen Grafschaft Surrey befindet. Der Boden ist dabei von einer Eis- und Schneeschicht überzogen, auf der die Musiker spielten.',\n",
                            "   \"Brian May sagte dazu später: “Looking back, it couldn't be done there – you couldn't do that!” („Wenn ich zurückschaue, hätte es nicht dort gemacht werden dürfen – man konnte das nicht tun!“)\",\n",
                            "   'Das Lied wurde mehrfach gecovert, unter anderem von der deutschen Metal-Band Blind Guardian auf ihrem 1992 erschienenen Album Somewhere Far Beyond. Weitere Coverversionen gibt es u. a. von Jeff Scott Soto und Shawn Mars.'],\n",
                            "  'url': 'https://de.wikipedia.org/wiki/Spread%20Your%20Wings'}}"
                        ]
                    },
                    "execution_count": 158,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from vespa.io import VespaQueryResponse\n",
                "\n",
                "\n",
                "response: VespaQueryResponse = app.query(\n",
                "    yql=\"select * from page where userQuery() or ({targetHits:1000, approximate:true}nearestNeighbor(binary_vectors,q_binary))\",\n",
                "    ranking=\"rerank\",\n",
                "    query=query,\n",
                "    language=\"de\",  # don't guess the language of the query\n",
                "    body={\n",
                "        \"presentation.format.tensors\": \"short-value\",\n",
                "        \"input.query(q_binary)\": query_emb.embeddings.binary[0],\n",
                "        \"input.query(q_full)\": query_emb.embeddings.float[0],\n",
                "        \"input.query(q_int8)\": query_emb.embeddings.int8[0],\n",
                "    },\n",
                ")\n",
                "assert response.is_successful()\n",
                "response.hits[0]"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bb8922bc",
            "metadata": {},
            "source": [
                "Notice the returned hits. The `relevance` is the score assigned by the second-phase expression. Also notice, that we included\n",
                "[bm25](https://docs.vespa.ai/en/reference/bm25.html) scores in the match-features. In this case, they do not influence ranking. The\n",
                "bm25 over chunks is calculated across all the elements, like if it was a bag of words or a single field string.\n",
                "\n",
                "We now have the full Wikipedia context for all the retrieved pages. We have all the chunks and all the cosine similarity scores for all the chunks in the wikipedia page,\n",
                "and no need to duplicate title and url into separate retrievable units like with single-vector databases.\n",
                "\n",
                "In RAG applications, we can now choose how much context we want to input to the generative step:\n",
                "\n",
                "- All the chunks\n",
                "- Only the best k chunks with a threshold on the cosine similarity\n",
                "- The adjacent chunks of the best chunk\n",
                "\n",
                "Or combinations of the above.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9b9f45d3",
            "metadata": {
                "id": "7c8b8223"
            },
            "source": [
                "## Conclusions\n",
                "\n",
                "These new Cohere binary embeddings are a huge step forward for cost-efficient vector search at scale and integrate perfectly\n",
                "with the rich feature set in Vespa. Including multilingual text search capabilities and hybrid search.\n",
                "\n",
                "### Clean up\n",
                "\n",
                "We can now delete the cloud instance:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7fb27b941602401d91542211134fc71a",
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "executionInfo": {
                    "elapsed": 3720,
                    "status": "ok",
                    "timestamp": 1705505103257,
                    "user": {
                        "displayName": "Andreas Eriksen",
                        "userId": "00161553861396505040"
                    },
                    "user_tz": -60
                },
                "id": "71e310e3",
                "outputId": "991b1965-6c33-4985-e873-a92c43695528"
            },
            "outputs": [],
            "source": [
                "vespa_cloud.delete()"
            ]
        }
    ],
    "metadata": {
        "colab": {
            "name": "",
            "provenance": [
                {
                    "file_id": "1FoVAybR6dhXy-uDkVuDfBtVzSJoresCB",
                    "timestamp": 1706644027750
                }
            ],
            "version": ""
        },
        "kernelspec": {
            "display_name": "Python 3.11.4 64-bit",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        },
        "vscode": {
            "interpreter": {
                "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}